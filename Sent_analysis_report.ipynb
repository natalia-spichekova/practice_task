{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sent_analysis_report.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_vimrndrxHbC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check envinroment"
      ]
    },
    {
      "metadata": {
        "id": "hP4GCKnYxPCW",
        "colab_type": "code",
        "outputId": "f6bd173c-18ca-4541-9276-b84eb87a21f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print sys.version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.7.15rc1 (default, Nov 12 2018, 14:31:15) \n",
            "[GCC 7.3.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iuM8Z_XBl9M3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Set up Colab"
      ]
    },
    {
      "metadata": {
        "id": "y-nL0mtymF5V",
        "colab_type": "code",
        "outputId": "b7007777-ae56-4c8a-c74a-b6d0dda75258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "# install pydrive to load daa and script files \n",
        "!pip install pydrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python2.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python2.7/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python2.7/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive) (0.11.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.4)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive) (1.11.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mjy85BwimWb8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook was prepared in Colab. To load data and python scripts in Colab, some additional steps are to be  performed. \n",
        "First, data archive and python scripts archive were uploaded in Google Drive and shared for public access.\n",
        "Then files were downloaded to Colab from Google Drive by means of the link. At last, the uploaded archives were extracted.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RlzX1LotwMBI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import tarfile\n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2vDMsQyHEJbO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2clPBWSby5pA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load and exctract data files in Colab\n",
        "\n",
        "# shared link to data archive file\n",
        "# https://drive.google.com/open?id=1iqg3npFMm-7EeqDbZbwOHJbms01lAjbC \n",
        "\n",
        "download = drive.CreateFile({'id': '1iqg3npFMm-7EeqDbZbwOHJbms01lAjbC'})\n",
        "download.GetContentFile('aclImdb_v1.tar.gz')\n",
        "\n",
        "# unzip\n",
        "if not os.path.exists('data'):\n",
        "  os.makedirs(\"data\")\n",
        "\n",
        "tar = tarfile.open('aclImdb_v1.tar.gz', \"r:gz\")\n",
        "tar.extractall('data/')\n",
        "tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ospR4rXU_Qec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load and extract python scripts\n",
        "\n",
        "# shared link to script files\n",
        "# https://drive.google.com/open?id=1CDNHqHBIToXXv8iUsDYNzmn-GI8eT5KG\n",
        "\n",
        "download_scr = drive.CreateFile({'id': '1CDNHqHBIToXXv8iUsDYNzmn-GI8eT5KG'})\n",
        "download_scr.GetContentFile('scripts.zip')\n",
        "\n",
        "zip_ref = zipfile.ZipFile('scripts.zip', \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JbhA8iq56OUN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset description"
      ]
    },
    {
      "metadata": {
        "id": "kUF7_hmO6VcD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The dataset, that is used to create the model, is a Large Movie Review Dataset v1.0. The dataset along with its description is available at http://ai.stanford.edu/~amaas/data/sentiment/\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Vr893qgYp4BD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ]
    },
    {
      "metadata": {
        "id": "EECprqdXqEo0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Read raw text data."
      ]
    },
    {
      "metadata": {
        "id": "_O5n9A-fqTec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import utils\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eh22syFF-46V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "\n",
        "train_path = os.path.join(\"data\", \"aclImdb\", \"train\")\n",
        "test_path = os.path.join(\"data\", \"aclImdb\", \"test\")\n",
        "\n",
        "train = utils.loaddata(train_path)\n",
        "test = utils.loaddata(test_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZH-yWJF3htOV",
        "colab_type": "code",
        "outputId": "0a4b970d-0f8d-4edc-c350-c1ab79612e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "print train[1][0], train[0][0]\n",
        "print train[1][12500], train[0][12500]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n",
            "1 Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UsENUWrZsuo-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Split train data into two subsets - train data and validation data in the proportion 70:30. We'll train models on the train subset and check model accuracy on the validation subset. Quality of the final model will be checked on test subset."
      ]
    },
    {
      "metadata": {
        "id": "mS9aECuSBYmd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split train set into train and validation \n",
        "train_data, val_data, train_target, val_target = train_test_split(train[0], train[1], shuffle=True, test_size=0.3, random_state=123)\n",
        "\n",
        "test_data = test[0]\n",
        "test_target = test[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OfwE_djF79Om",
        "colab_type": "code",
        "outputId": "b68d4680-8631-4334-f807-4239f267b6f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "train_data[0:3]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[u'I created my own reality by walking out of the theater I was roped in by my girlfriend into going to this dreck with her mom. We (my g-friend and I) walked out about an hour into it. What a load of pseudo scientific new age jargon.<br /><br />Sub atomic particles are thoughts? By taping labels to bottles of water and blessing it by a Buddhist monk it grew little pretty crystals? A drop of 25% in the murder rate in DC happened when a bunch of folks meditated. Wow, what a rigorous scientific study. I\\'m sure that someone ate cheerios for four days straight during the same time. Should we conclude that eating cheerios caused a drop in the murder rate? <br /><br />Hogwash, hooey, bull pucky! <br /><br />BTW- It was funded by the Ramtha cult, the leader of which was one of the \"experts\" which were interview by the filmmakers. No ulterior motives here, right?',\n",
              " u'The most horrible retelling of a great series. It should not have been named Battlestar Galactica, because it\\'s only the same in name alone. Too many changes to just have changes. You have characters turned from male to female, black to asian to cylon all in a way to \"attract female audiences,\" when there was already strong female characters that could have just been made stronger. Gone are the egyptian feeling. Gone are the quest for earth. The lack of cylons to go to terminator rejects takes away from the film, especially when one is made a fembot. Granted the original show had a lot of cheese to it, but it had a large following. They tried to hold onto this following but give the fans nothing to work with and basically spit in their face as they make it \"their own story.\" Changes are good, when they make something better, not to just make them.',\n",
              " u\"***SPOILERS*** ***SPOILERS*** Packed with memorable moments (such as the quote above, immortalized by Primus), Deliverance tells the story of four guys who take a trip to the wild woods to go white water rafting and get away from the big city for a while only to find that their fun soon takes a bad turn. This is not a Hollywood film. There are virtually no special effects whatsoever, the setting is extremely realistic, and nothing at all is sugarcoated or made pretty. The city boys look like city boys, and even the tough guy Louis, portrayed with precision by Burt Reynolds, is clearly at the mercy of the wild on this trip. This is a perfect example of a what-if film. What if a few friends went river rafting in an area of the woods that none of them were familiar with, and ended up desperately trying to avoid being tried and convicted for murders that they were forced to commit to save their own lives?<br /><br />There is clearly a very strong element of the film that deals with societal and class structure and the relationship (or lack thereof) between rural and urban peoples. When the four guys arrive in the woods early in the film, they clearly do not quite know how to interact with the people who live out there, and they speak to them as though they are unsure whether they will understand or be able to communicate. This communication block is most memorably illustrated in the dueling banjoes scene, in which they are trying to gas up the car and truck and get someone to drive the vehicles downriver for them. While Drew and the obviously inbred and probably mentally deficient boy on the porch are dueling with their guitar and banjo (one of the best scenes in the film), Louis is having some difficulty buying the gas, and Bobby makes a comment about genetic deficiencies and how pathetic it all is. When the boy turns away from Drew, who had offered to shake his hand after their stupendous jam session, Bobby tells him to give the kid a couple bucks, knowing that none of them are quite sure how to react.<br /><br />This is the kind of thing that we see in Deliverance that sets up so much of the tension that is to follow. This great scene where a lot of fun was had (including the funniest 'redneck dancing' scene until O Brother, Where Art Thou?) ended with everyone awkwardly unsure what to do around each other. These people are apples and oranges, and they live by completely different rules of life. The people that Louis, Bobby, Drew and Ed encounter in the hills grew up separated from modern society and modern laws, and live by the rules of nature, which do not include thou shalt not kill. Confused by their awkward behavior, the four friends set out on the river, hoping for the weirdness to end and for the adventure to begin.<br /><br />(spoilers) When they are briefly separated from each other and Ed and Bobby run into the hillbillies beside the river who quickly turn unpleasant, the uncertainty about the way that these people live - which was established by the scene above - comes into play to create the most tension during the scene. I think that a good sign of a quality thriller like this is that the tragic element of the film, namely the assaults and actual murders, takes up a very small amount of screen time but remain some of the most memorable parts of the film. There is no gratuitous violence here, it's all there for an obvious purpose and it achieves a startlingly powerful effect.<br /><br />The move is about the violent clash of two very different kinds of people, and what can happen when they inadvertently find themselves at war with each other. The trip down the rest of the river after the assault, which takes up the majority of the film, delivers some spectacularly effective tension, and keeps you on the edge of your seat while not bombarding you with so much happening that you become numb. It is surprisingly effective when we find out that Ed may very well have killed the wrong man up there on the cliff, and the tension in the film doesn't even let up when the three surviving members of the team reach the bottom of the river, because they deliver a questionable explanation to the police about what happened up there on the river and why the deputy's brother-in-law is missing.<br /><br />This is a very disturbing film, which is a testament to its success, because it's pretty obvious that a film like this is meant to shake people up a little bit. The hillbillies are the human (i.e. more realistic) version of the sub-human rednecks seen in childish but fairly similar films like Gator Bait and Gator Bait 2, neither of which could possibly ever be compared to a timeless film like Deliverance. When we follow these four men through their fateful weekend in the woods, the natural element is so real and we get to know the men so well and in such a subtle fashion that it's almost like we, as individuals of the audience, are really a fifth member of the team. It's not often that a film is able to come across that way.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "mFqxtCpW21ag",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Preprocess data"
      ]
    },
    {
      "metadata": {
        "id": "PpCz2DoO2-_M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following rules are applied during preprocessing:\n",
        "\n",
        "1. characters are  converted to lowercase \n",
        "2. contracted forms are replaced with the corresponding full forms\n",
        "3. some special characters like (), {}, !,, etc are replaced with space\n",
        "4. characters that are not digits, letters, space, underscore or \"#\", \"+\" are removed\n",
        "5. stopwords are removed.\n",
        "\n",
        "To filter stopwords, stopwords corpus from nltk python package is used. Words 'no', 'nor', 'not' are assumed to be important for sentiment analysis and are excluded from the stopwords corpus.\n",
        "\n",
        "Patterns to be replaced are defined with regular expressions. More details on the replacement rules can be found in \"process.py\" file.\n"
      ]
    },
    {
      "metadata": {
        "id": "ZNdyWTldBlsS",
        "colab_type": "code",
        "outputId": "4d2f4590-0f33-4565-af9e-d950995d67e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "from preprocess import TextPreprocessor"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tq3Bz2UG2543",
        "colab_type": "code",
        "outputId": "749bd13d-65e7-4fd7-f80f-f9824cd06e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "# preprocess data\n",
        "prp = TextPreprocessor()\n",
        "\n",
        "X_train_tok = [prp.clean_text(text) for text in train_data]\n",
        "print('train subset is preprocessed')\n",
        "X_val_tok = [prp.clean_text(text) for text in val_data]\n",
        "print('validation subset is preprocessed')\n",
        "X_test_tok = [prp.clean_text(text) for text in test_data]\n",
        "print('test subset is preprocessed')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train subset is preprocessed\n",
            "validation subset is preprocessed\n",
            "test subset is preprocessed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qo7ZQKRJ_xxk",
        "colab_type": "code",
        "outputId": "5d3dcea6-73a9-4ebf-f593-a3f8c0359155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "# example of the preproccessed text\n",
        "X_train_tok[0:3]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[u'created reality walking theater roped girlfriend going dreck mom g friend walked hour load pseudo scientific new age jargon sub atomic particles thoughts taping labels bottles water blessing buddhist monk grew little pretty crystals drop 25 murder rate dc happened bunch folks meditated wow rigorous scientific study sure someone ate cheerios four days straight time conclude eating cheerios caused drop murder rate hogwash hooey bull pucky btw funded ramtha cult leader one experts interview filmmakers no ulterior motives right',\n",
              " u'horrible retelling great series not named battlestar galactica name alone many changes changes characters turned male female black asian cylon way attract female audiences already strong female characters could made stronger gone egyptian feeling gone quest earth lack cylons go terminator rejects takes away film especially one made fembot granted original show lot cheese large following tried hold onto following give fans nothing work basically spit face make story changes good make something better not make',\n",
              " u'spoilers spoilers packed memorable moments quote immortalized primus deliverance tells story four guys take trip wild woods go white water rafting get away big city find fun soon takes bad turn not hollywood film virtually no special effects whatsoever setting extremely realistic nothing sugarcoated made pretty city boys look like city boys even tough guy louis portrayed precision burt reynolds clearly mercy wild trip perfect example film friends went river rafting area woods none familiar ended desperately trying avoid tried convicted murders forced commit save lives clearly strong element film deals societal class structure relationship lack thereof rural urban peoples four guys arrive woods early film clearly not quite know interact people live speak though unsure whether understand able communicate communication block memorably illustrated dueling banjoes scene trying gas car truck get someone drive vehicles downriver drew obviously inbred probably mentally deficient boy porch dueling guitar banjo one best scenes film louis difficulty buying gas bobby makes comment genetic deficiencies pathetic boy turns away drew offered shake hand stupendous jam session bobby tells give kid couple bucks knowing none quite sure react kind thing see deliverance sets much tension follow great scene lot fun including funniest redneck dancing scene brother art thou ended everyone awkwardly unsure around people apples oranges live completely different rules life people louis bobby drew ed encounter hills grew separated modern society modern laws live rules nature not include thou shalt not kill confused awkward behavior four friends set river hoping weirdness end adventure begin spoilers briefly separated ed bobby run hillbillies beside river quickly turn unpleasant uncertainty way people live established scene comes play create tension scene think good sign quality thriller like tragic element film namely assaults actual murders takes small amount screen time remain memorable parts film no gratuitous violence obvious purpose achieves startlingly powerful effect move violent clash two different kinds people happen inadvertently find war trip rest river assault takes majority film delivers spectacularly effective tension keeps edge seat not bombarding much happening become numb surprisingly effective find ed may well killed wrong man cliff tension film not even let three surviving members team reach bottom river deliver questionable explanation police happened river deputy brother law missing disturbing film testament success pretty obvious film like meant shake people little bit hillbillies human e realistic version sub human rednecks seen childish fairly similar films like gator bait gator bait 2 neither could possibly ever compared timeless film like deliverance follow four men fateful weekend woods natural element real get know men well subtle fashion almost like individuals audience really fifth member team not often film able come across way']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "eK1JuXd7iGG-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's check what is length of the review texts. We'll do calculations for the train dataset."
      ]
    },
    {
      "metadata": {
        "id": "qSjzY76fiFYG",
        "colab_type": "code",
        "outputId": "2971d989-4c19-4472-ba24-bfda1a6c2658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns \n",
        "import numpy as np\n",
        "\n",
        "review_len = [len(text) for text in X_train_tok]\n",
        "print \"Mean \", np.mean(review_len) \n",
        "print \"std \", np.std(review_len)\n",
        "\n",
        "sns.boxplot(review_len)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean  838.9772571428572\n",
            "std  643.7283114992067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/seaborn/categorical.py:454: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
            "  box_data = remove_na(group_data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f92e8f058d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdYAAAFKCAYAAACgvn5iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4OhJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4P2_iqCmjwti",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the plot above it follows that the 75th percentile approximately equals to 1000. It means that 75% of lengths of review texts in X_train_tok set is below 1000. "
      ]
    },
    {
      "metadata": {
        "id": "L_OeAxQV_cIM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Approach based on logistic regression"
      ]
    },
    {
      "metadata": {
        "id": "voEDdAJ75qVG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The idea is to create tf-idf features for documents (i.e reviews) and apply logistic regression algorithm to a matrix of tf-idf features. Instead of tf-idf, bag-of-words approach can be used to generate document features. Tf-idf approach was selected because usually it provides better results. "
      ]
    },
    {
      "metadata": {
        "id": "aCvXFfk_DqHb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When creating a matrix with tf-idf features for sentiment analysis, it is reasonable to take into account both 1-and 2- grams. Let's check number of ngrams and their frequency in the corpus:"
      ]
    },
    {
      "metadata": {
        "id": "NIy7LpFPDSxj",
        "colab_type": "code",
        "outputId": "0d3b7ce4-49f6-4fad-a592-ee7aa4154ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cnt_vect = CountVectorizer(ngram_range=(1, 2), max_df=0.9, min_df=5)\n",
        "bag_of_words = cnt_vect.fit_transform(X_train_tok)\n",
        "\n",
        "print \"Total number of ngrams: \", bag_of_words.shape[1]\n",
        "\n",
        "# ngrams in the corpus\n",
        "sum_words = bag_of_words.toarray().sum(axis=0)\n",
        "\n",
        "# ngrams and their frequencies in the corpus\n",
        "ngrams_dict = {word: freq for word, freq in zip(cnt_vect.get_feature_names(), sum_words)}\n",
        "# sort ngrams by the frequency in reverse order\n",
        "ngrams_dict_sorted = sorted(ngrams_dict.items(), key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of ngrams:  65821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2amRoL-WMWMg",
        "colab_type": "code",
        "outputId": "e031c350-29c0-43be-c51b-6ba2b6b5780f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "N = 12000\n",
        "ngrams_dict_sorted[N:][0:5]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(u'gets better', 28),\n",
              " (u'cracker', 28),\n",
              " (u'tin', 28),\n",
              " (u'matter much', 28),\n",
              " (u'gusto', 28)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "YYkZ-2qZQEE3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Top of N=12000 ngrams has frequency higher than 30. Other ngrams are  less frequent.  It seems rather reasonable to preserve a top of N=12000 ngrams in the dictionary. "
      ]
    },
    {
      "metadata": {
        "id": "Vi9_O2MUSIkH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create tf-idf features :"
      ]
    },
    {
      "metadata": {
        "id": "zCkJkbVUEzj_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from models import Model\n",
        "\n",
        "m = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cOMmmH6xUmPx",
        "colab_type": "code",
        "outputId": "0564730c-198b-45fb-fa5a-2ca8fba3d45a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# get tfidt features\n",
        "X_train_tfidf_tok, tfidf_vect = m.tfidf_train(X_train_tok, ngram_range=(1,2), max_df=0.9, \n",
        "                                       min_df=5, max_features=12000)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 25.8 s, sys: 355 ms, total: 26.1 s\n",
            "Wall time: 26.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D9D17mefUrGZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_val_tfidf_tok = m.tfidf_trans(tfidf_vect, X_val_tok)\n",
        "X_test_tfidf_tok = m.tfidf_trans(tfidf_vect, X_test_tok)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wd2b2o_CR-8x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fit LogisticRegression classifier"
      ]
    },
    {
      "metadata": {
        "id": "0YY4lzlmSb8B",
        "colab_type": "code",
        "outputId": "b8e64dd3-920b-4ee4-c09c-0acea59bbde1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "clf_regr_tok = m.log_regression_train(X_train_tfidf_tok, train_target)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.21 s, sys: 629 ms, total: 1.84 s\n",
            "Wall time: 28.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JDoRXQaCSen4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check the classifier accuracy on validation set:"
      ]
    },
    {
      "metadata": {
        "id": "zYI3hLhdIBTH",
        "colab_type": "code",
        "outputId": "e6f0de19-7d19-4d9e-ba83-b82b48e3642d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "lr_acc_val, lr_cvs_val = m.check_acc(clf_regr_tok, X_val_tfidf_tok, val_target)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy:  0.8912\n",
            "Cross validation score:  [0.868      0.86733333 0.88933333 0.87733333 0.88266667]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rl3ZN_-1Vdoc",
        "colab_type": "code",
        "outputId": "6596a338-a12f-482a-b88f-b145f6d327f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "lr_acc_test, lr_cvs_test = m.check_acc(clf_regr_tok, X_test_tfidf_tok, test_target)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy:  0.87648\n",
            "Cross validation score:  [0.8882 0.8792 0.8864 0.8848 0.8726]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FNWYuW5es47x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "KPCRpuzDs-Ci",
        "colab_type": "code",
        "outputId": "261ae3eb-569b-4bd2-b408-ebb2f2ee0064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(val_target, m.pred_labeles(clf_regr_tok, X_val_tfidf_tok)).ravel()\n",
        "print lr_tn, lr_fp, lr_fn, lr_tp"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3249 456 360 3435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qQZ-fVVqWk0L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save results of model evaluation in DataFrame"
      ]
    },
    {
      "metadata": {
        "id": "qNAkb-GZVo40",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "models_acc = pd.DataFrame({'model_name': [\"log_regr\"], \n",
        "                           'acc_on_val': [lr_acc_val], \\\n",
        "                           'cross_val_score_mean_val': [np.mean(lr_cvs_val)], \\\n",
        "                           'acc_on_test': [lr_acc_test], \n",
        "                           'cross_val_score_mean_test': [np.mean(lr_cvs_test)],\n",
        "                           'TN': lr_tn,\n",
        "                           'FP': lr_fp,\n",
        "                           'FN': lr_fn,\n",
        "                           'TP': lr_tp})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PMuBGuIyX3AV",
        "colab_type": "code",
        "outputId": "d4b9db0a-5ec2-4c7f-a041-493d0d3d7482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "cell_type": "code",
      "source": [
        "models_acc"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FN</th>\n",
              "      <th>FP</th>\n",
              "      <th>TN</th>\n",
              "      <th>TP</th>\n",
              "      <th>acc_on_test</th>\n",
              "      <th>acc_on_val</th>\n",
              "      <th>cross_val_score_mean_test</th>\n",
              "      <th>cross_val_score_mean_val</th>\n",
              "      <th>model_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360</td>\n",
              "      <td>456</td>\n",
              "      <td>3249</td>\n",
              "      <td>3435</td>\n",
              "      <td>0.87648</td>\n",
              "      <td>0.8912</td>\n",
              "      <td>0.88224</td>\n",
              "      <td>0.876933</td>\n",
              "      <td>log_regr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    FN   FP    TN    TP  acc_on_test  acc_on_val  cross_val_score_mean_test  \\\n",
              "0  360  456  3249  3435      0.87648      0.8912                    0.88224   \n",
              "\n",
              "   cross_val_score_mean_val model_name  \n",
              "0                  0.876933   log_regr  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "5_WjMZqVXh38",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Other classifiers such as SVC, Random Forest, AdaBoost,  GradientBoostingClassifier were tested as well. They have lower accuracy. Tuning parameters of these classifiers require much time due to sparsity of feature matrix. Results of their evaluation are not listed here."
      ]
    },
    {
      "metadata": {
        "id": "j92RS9W8lNxK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Upload the model files to Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "6QUevtE7lSac",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from models import MODEL_PATH\n",
        "\n",
        "def upload_to_GD(file_list):\n",
        "  for file in file_list:\n",
        "    upload = drive.CreateFile({'title': file})\n",
        "    upload.SetContentFile(file)\n",
        "    upload.Upload()\n",
        "\n",
        "file_list = [MODEL_PATH[\"TFIDF_VECTORIZER\"], MODEL_PATH[\"LOG_REGR_CLASSIFIER\"]]\n",
        "upload_to_GD(file_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RWG0DOGucF3I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sentiment analysis with Doc2Vec model"
      ]
    },
    {
      "metadata": {
        "id": "lGulb3WHcJ2P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Doc2Vec is an algorithm to convert sentences / documents into numeric vectors. The idea is to get numeric representation of movie reviews and then apply a classification algorithm to the numeric vectors. Length of vectors is taken equal to 100.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "uyLIVhuwcgBT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import Doc2Vec\n",
        "from doc2vec_model import Doc2Vec_Model, DOC2VEC_MODEL_PATH\n",
        "\n",
        "\n",
        "d2v_model = Doc2Vec_Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DxP3Vj9FcyTz",
        "colab_type": "code",
        "outputId": "4f9bddd0-8c2b-4646-b594-cc4cad682463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# train and save doc2vec model\n",
        "import multiprocessing\n",
        "cores=multiprocessing.cpu_count()\n",
        "\n",
        "d2v_model.doc2vec_train(X_train_tok, vec_size=100, max_epochs=10, workers=cores)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0\n",
            "iteration 2\n",
            "iteration 4\n",
            "iteration 6\n",
            "iteration 8\n",
            "Model Saved\n",
            "CPU times: user 21min 28s, sys: 34.3 s, total: 22min 3s\n",
            "Wall time: 12min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SL2xn0UYc6K_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load model\n",
        "d2v = Doc2Vec.load(DOC2VEC_MODEL_PATH[\"DOC2VEC\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vdxJfAxdgOGt",
        "colab_type": "code",
        "outputId": "ded79025-55e3-40db-ffce-84630b3a2219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# get numeric representation for documents from corpus\n",
        "X_train_d2v = d2v_model.doc2vec_infer(d2v, X_train_tok)\n",
        "X_val_d2v = d2v_model.doc2vec_infer(d2v, X_val_tok)\n",
        "X_test_d2v = d2v_model.doc2vec_infer(d2v, X_test_tok)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 6s, sys: 168 ms, total: 4min 6s\n",
            "Wall time: 4min 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8JtU2VS7iti-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train logistic regression on vector representation of the documents and evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "POX0Q8TiisyH",
        "colab_type": "code",
        "outputId": "b2eb1b43-c41f-4fb3-b3e3-d763ad2258b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "lr_d2v_tok = m.log_regression_train(X_train_d2v, train_target, model_file=MODEL_PATH[\"LOG_REGR_DOC2VEC_CLASSIFIER\"])\n",
        "d2v_acc_val, d2v_cvs_val = m.check_acc(lr_d2v_tok, X_val_d2v, val_target)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy:  0.8818666666666667\n",
            "Cross validation score:  [0.868      0.874      0.87866667 0.894      0.89533333]\n",
            "CPU times: user 2min, sys: 2.96 s, total: 2min 3s\n",
            "Wall time: 3min 20s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KYZUQQFUljq_",
        "colab_type": "code",
        "outputId": "00f98ba1-919a-470b-8dda-ef6eab4c730e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "d2v_acc_test, d2v_cvs_test = m.check_acc(lr_d2v_tok, X_test_d2v, test_target)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy:  0.87264\n",
            "Cross validation score:  [0.8792 0.8818 0.8796 0.8732 0.8616]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cA5_B9Y0t2OZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "B1lzjT6Ptq7U",
        "colab_type": "code",
        "outputId": "88fe065d-2a30-42e7-80f3-c5c73b927640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "d2v_tn, d2v_fp, d2v_fn, d2v_tp = confusion_matrix(val_target, m.pred_labeles(lr_d2v_tok, X_val_d2v)).ravel()\n",
        "print d2v_tn, d2v_fp, d2v_fn, d2v_tp"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3281 424 462 3333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9TM8aef7tosE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save results of model evaluation"
      ]
    },
    {
      "metadata": {
        "id": "mJZ7SqHGnSxm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models_acc_d2 = pd.DataFrame({'model_name': [\"d2v\"], \n",
        "                              'acc_on_val': [d2v_acc_val], \\\n",
        "                              'cross_val_score_mean_val': [np.mean(d2v_cvs_val)], \\\n",
        "                              'acc_on_test': [d2v_acc_test], \n",
        "                              'cross_val_score_mean_test': [np.mean(d2v_cvs_test)],\n",
        "                              'TN': d2v_tn,\n",
        "                              'FP': d2v_fp,\n",
        "                              'FN': d2v_fn,\n",
        "                              'TP': d2v_tp})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z1Up-1wdneOC",
        "colab_type": "code",
        "outputId": "10e71248-4e4f-435a-f6f3-a8ef8a4e3d0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "cell_type": "code",
      "source": [
        "models_acc = models_acc.append(models_acc_d2)\n",
        "models_acc"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FN</th>\n",
              "      <th>FP</th>\n",
              "      <th>TN</th>\n",
              "      <th>TP</th>\n",
              "      <th>acc_on_test</th>\n",
              "      <th>acc_on_val</th>\n",
              "      <th>cross_val_score_mean_test</th>\n",
              "      <th>cross_val_score_mean_val</th>\n",
              "      <th>model_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360</td>\n",
              "      <td>456</td>\n",
              "      <td>3249</td>\n",
              "      <td>3435</td>\n",
              "      <td>0.87648</td>\n",
              "      <td>0.891200</td>\n",
              "      <td>0.88224</td>\n",
              "      <td>0.876933</td>\n",
              "      <td>log_regr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>462</td>\n",
              "      <td>424</td>\n",
              "      <td>3281</td>\n",
              "      <td>3333</td>\n",
              "      <td>0.87264</td>\n",
              "      <td>0.881867</td>\n",
              "      <td>0.87508</td>\n",
              "      <td>0.882000</td>\n",
              "      <td>d2v</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    FN   FP    TN    TP  acc_on_test  acc_on_val  cross_val_score_mean_test  \\\n",
              "0  360  456  3249  3435      0.87648    0.891200                    0.88224   \n",
              "0  462  424  3281  3333      0.87264    0.881867                    0.87508   \n",
              "\n",
              "   cross_val_score_mean_val model_name  \n",
              "0                  0.876933   log_regr  \n",
              "0                  0.882000        d2v  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "Tjd7phOXl5FC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save the trained model on Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "-yNiGeCJl5bC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_list = [DOC2VEC_MODEL_PATH[\"DOC2VEC\"], MODEL_PATH[\"LOG_REGR_DOC2VEC_CLASSIFIER\"]]\n",
        "upload_to_GD(file_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JAfbsiTIqurx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Sentiment analysis with TextBlob library"
      ]
    },
    {
      "metadata": {
        "id": "cFFOlo3VuE49",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TextBlob library can generate *polarity* *score* for  a given text. Polarity score is a float within the range [-1;1]"
      ]
    },
    {
      "metadata": {
        "id": "wanKkh0fkNMm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# get sentiment property for train, validation and test subsets\n",
        "train_pol = np.asarray([TextBlob(text).sentiment[0] for text in X_train_tok]).reshape(-1, 1)\n",
        "val_pol = np.asarray([TextBlob(text).sentiment[0] for text in X_val_tok]).reshape(-1, 1)\n",
        "test_pol = np.asarray([TextBlob(text).sentiment[0] for text in X_test_tok]).reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X7mn5wvxdWLt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Apply logistic regression classifier to polarity scores to classify reviews. For classification a rule based on threshold can be applied. But I found that logistic classifier has better accuracy."
      ]
    },
    {
      "metadata": {
        "id": "d5CLHSnmrDg7",
        "colab_type": "code",
        "outputId": "e19bc9ba-00b8-451d-9028-4f928c2c27ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pol_clf = m.log_regression_train(train_pol, train_target, model_file=MODEL_PATH[\"LOG_REGR_POLARITY_CLASSIFIER\"])\n",
        "pol_acc_val, pol_cvs_val = m.check_acc(pol_clf, val_pol, val_target)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy:  0.7764\n",
            "Cross validation score:  [0.782      0.77866667 0.77866667 0.78266667 0.78133333]\n",
            "CPU times: user 607 ms, sys: 53.7 ms, total: 660 ms\n",
            "Wall time: 2.49 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qxUd0ybptei-",
        "colab_type": "code",
        "outputId": "0920abac-1c30-4735-af8d-eda749e62bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "pol_acc_test, pol_cvs_test = m.check_acc(pol_clf, test_pol, test_target)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy:  0.77196\n",
            "Cross validation score:  [0.7796 0.7654 0.772  0.7616 0.7788]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_bdpTY68uIsZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "u7HW_FrGuH9g",
        "colab_type": "code",
        "outputId": "997079e1-0243-4174-9705-691d98f7159b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "pol_tn, pol_fp, pol_fn, pol_tp = confusion_matrix(val_target, m.pred_labeles(pol_clf, val_pol)).ravel()\n",
        "print pol_tn, pol_fp, pol_fn, pol_tp"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2813 892 785 3010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5nH1cU8ut4Kk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models_acc_pol = pd.DataFrame({'model_name': [\"pol\"], \n",
        "                               'acc_on_val': [pol_acc_val], \\\n",
        "                               'cross_val_score_mean_val': [np.mean(pol_cvs_val)], \\\n",
        "                               'acc_on_test': [pol_acc_test], \n",
        "                               'cross_val_score_mean_test': [np.mean(pol_cvs_test)],\n",
        "                               'TN': pol_tn,\n",
        "                               'FP': pol_fp,\n",
        "                               'FN': pol_fn,\n",
        "                               'TP': pol_tp})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8t7D-zWhhQB2",
        "colab_type": "code",
        "outputId": "e3515948-e9ae-43fd-cfac-0148f620a465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "cell_type": "code",
      "source": [
        "models_acc = models_acc.append(models_acc_pol)\n",
        "models_acc"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FN</th>\n",
              "      <th>FP</th>\n",
              "      <th>TN</th>\n",
              "      <th>TP</th>\n",
              "      <th>acc_on_test</th>\n",
              "      <th>acc_on_val</th>\n",
              "      <th>cross_val_score_mean_test</th>\n",
              "      <th>cross_val_score_mean_val</th>\n",
              "      <th>model_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360</td>\n",
              "      <td>456</td>\n",
              "      <td>3249</td>\n",
              "      <td>3435</td>\n",
              "      <td>0.87648</td>\n",
              "      <td>0.891200</td>\n",
              "      <td>0.88224</td>\n",
              "      <td>0.876933</td>\n",
              "      <td>log_regr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>462</td>\n",
              "      <td>424</td>\n",
              "      <td>3281</td>\n",
              "      <td>3333</td>\n",
              "      <td>0.87264</td>\n",
              "      <td>0.881867</td>\n",
              "      <td>0.87508</td>\n",
              "      <td>0.882000</td>\n",
              "      <td>d2v</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>785</td>\n",
              "      <td>892</td>\n",
              "      <td>2813</td>\n",
              "      <td>3010</td>\n",
              "      <td>0.77196</td>\n",
              "      <td>0.776400</td>\n",
              "      <td>0.77148</td>\n",
              "      <td>0.780667</td>\n",
              "      <td>pol</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    FN   FP    TN    TP  acc_on_test  acc_on_val  cross_val_score_mean_test  \\\n",
              "0  360  456  3249  3435      0.87648    0.891200                    0.88224   \n",
              "0  462  424  3281  3333      0.87264    0.881867                    0.87508   \n",
              "0  785  892  2813  3010      0.77196    0.776400                    0.77148   \n",
              "\n",
              "   cross_val_score_mean_val model_name  \n",
              "0                  0.876933   log_regr  \n",
              "0                  0.882000        d2v  \n",
              "0                  0.780667        pol  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "wmKSMcvQkrzm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save the trained classifier on Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "5WYhfj88kq1E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_list = [MODEL_PATH[\"LOG_REGR_POLARITY_CLASSIFIER\"]]\n",
        "upload_to_GD(file_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dpBLq5a7lCGj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural netwoks models"
      ]
    },
    {
      "metadata": {
        "id": "UeZbD9cdp_fZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check frequencies of words."
      ]
    },
    {
      "metadata": {
        "id": "Xnkktsclp9uH",
        "colab_type": "code",
        "outputId": "465e757f-c702-4005-d96d-0cbb748f103c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "# find frequencies of words in X_train_tok dataset\n",
        "words_counts = Counter(list(itertools.chain.from_iterable(list(map(lambda x: x.split(), X_train_tok)))))\n",
        "\n",
        "print \"Mean \", np.mean(words_counts.values()) \n",
        "print \"std \", np.std(words_counts.values())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean  33.5034287832453\n",
            "std  334.7098464408595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NYBPDPq5tIwj",
        "colab_type": "code",
        "outputId": "2d02732a-f0ed-4f3d-98f0-77396914b9d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# sort word frequencies\n",
        "sorted_counts = sorted(list(words_counts.values()), reverse=True)\n",
        "sorted_counts[10000:10005]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[21, 21, 21, 21, 21]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "Z-h_lnVkpT3R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It means that top of 10000 words has frequency higher that 22. We'll include top 10000 words in the dictionary."
      ]
    },
    {
      "metadata": {
        "id": "_oQZgl9rtV0u",
        "colab_type": "code",
        "outputId": "c264972d-443e-4c25-f979-d46bc8a4dc2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from nn_models import NN_Data_Prepare, NN_Model, NN_Train_Predict, NN_MODEL_PATH\n",
        "\n",
        "DICT_SIZE = 10000\n",
        "# create dictionary\n",
        "nn_data_prepare = NN_Data_Prepare(dict_size=DICT_SIZE)\n",
        "nn_data_prepare.create_dict(X_train_tok)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ewbp3eJuM8pw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert lables to float format\n",
        "train_labels = nn_data_prepare.vectorized_labels(train_target)\n",
        "val_labels = nn_data_prepare.vectorized_labels(val_target)\n",
        "test_labels = nn_data_prepare.vectorized_labels(test_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lrVq35Srtpe4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll create two neural networks models."
      ]
    },
    {
      "metadata": {
        "id": "ZPBa0XZ6txRA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural network model 1"
      ]
    },
    {
      "metadata": {
        "id": "46XhaVpGt4R2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first neural network is a dense neural network. It gets one-hot representation of text reviews as input. One-hot representation of a text is a binary vector of length equal to dictionary size. The *i*-th component of the vector equals to 1 if the *i*-th word from the dictionary presents in the text at least once.  "
      ]
    },
    {
      "metadata": {
        "id": "YBOIZzaijLI5",
        "colab_type": "code",
        "outputId": "9dcbc013-5127-4950-febb-4b82e6c9a89d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# create one-hot-encoding representation of input data\n",
        "X_train_ohe = nn_data_prepare.set_ohe(X_train_tok)\n",
        "X_val_ohe = nn_data_prepare.set_ohe(X_val_tok)\n",
        "X_test_ohe = nn_data_prepare.set_ohe(X_test_tok)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 57min, sys: 742 ms, total: 57min 1s\n",
            "Wall time: 57min 2s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WJTOGllMNyft",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create dense model"
      ]
    },
    {
      "metadata": {
        "id": "6Ox6EXb2DhsJ",
        "colab_type": "code",
        "outputId": "168b185d-f076-49dd-9d61-96f45c4fa38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        }
      },
      "cell_type": "code",
      "source": [
        "from nn_models import NN_Model\n",
        "#import nn_models\n",
        "nn_model= NN_Model()\n",
        "dense_model = nn_model.dense_model()\n",
        "dense_model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 16)                160016    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,577\n",
            "Trainable params: 160,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L9uDFrC7Pk21",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fit model"
      ]
    },
    {
      "metadata": {
        "id": "DZxgIzX1Otui",
        "colab_type": "code",
        "outputId": "46ecd90e-184e-422d-becb-5cb11de6baf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "cell_type": "code",
      "source": [
        "nn_train = NN_Train_Predict()\n",
        "hist = nn_train.compile_and_fit_model(dense_model, X_train_ohe, train_labels, X_val_ohe, val_labels, path_to_save=NN_MODEL_PATH[\"DENSE_MODEL\"])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 17500 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "17500/17500 [==============================] - 13s 738us/step - loss: 0.5157 - binary_accuracy: 0.7366 - val_loss: 0.3191 - val_binary_accuracy: 0.8759\n",
            "Epoch 2/20\n",
            "17500/17500 [==============================] - 13s 747us/step - loss: 0.3185 - binary_accuracy: 0.8794 - val_loss: 0.2987 - val_binary_accuracy: 0.8833\n",
            "Epoch 3/20\n",
            "17500/17500 [==============================] - 33s 2ms/step - loss: 0.2492 - binary_accuracy: 0.9083 - val_loss: 0.3000 - val_binary_accuracy: 0.8835\n",
            "Epoch 4/20\n",
            "17500/17500 [==============================] - 34s 2ms/step - loss: 0.1930 - binary_accuracy: 0.9293 - val_loss: 0.3555 - val_binary_accuracy: 0.8816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4htIHhY2g8hT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "nBmRAhilffkk",
        "colab_type": "code",
        "outputId": "8e80b8a6-846d-4155-a4de-093d740b1425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "dense_model = load_model(NN_MODEL_PATH[\"DENSE_MODEL\"])\n",
        "dense_loss_val, dense_acc_val = nn_train.model_evaluate(dense_model, X_val_ohe, val_labels)\n",
        "print \"Validation set. loss: \", dense_loss_val, \", accuracy: \", dense_acc_val \n",
        "dense_loss_test, dense_acc_test = nn_train.model_evaluate(dense_model, X_test_ohe, test_labels)\n",
        "print \"Test set. loss: \", dense_loss_test, \", accuracy: \", dense_acc_test "
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7500/7500 [==============================] - 10s 1ms/step\n",
            "Validation set. loss:  0.29871259900728864 , accuracy:  0.8833333333015442\n",
            "25000/25000 [==============================] - 20s 807us/step\n",
            "Test set. loss:  0.30592166874945165 , accuracy:  0.87504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g1AKucoyunMM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "CIq7jbkfhwna",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get predicted class labels\n",
        "dense_predicted_classes = nn_train.model_predict_classes(dense_model, X_val_ohe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4KSXnug5iBWI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ded9a61b-84a5-4d9d-9538-847276120c6c"
      },
      "cell_type": "code",
      "source": [
        "dense_tn, dense_fp, dense_fn, dense_tp = confusion_matrix(val_labels, dense_predicted_classes.flatten()).ravel()\n",
        "print dense_tn, dense_fp, dense_fn, dense_tp"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3274 431 444 3351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SRPAmDQRwLoN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save results of evaluation"
      ]
    },
    {
      "metadata": {
        "id": "mKGQLxyNiyFQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models_acc_dense_model = pd.DataFrame({'model_name': [\"dense_model\"], \n",
        "                                       'acc_on_val': dense_acc_val, \\\n",
        "                                       'cross_val_score_mean_val': None, \\\n",
        "                                       'acc_on_test': dense_acc_test, \n",
        "                                       'cross_val_score_mean_test': None,\n",
        "                                       'TN': dense_tn,\n",
        "                                       'FP': dense_fp,\n",
        "                                       'FN': dense_fn,\n",
        "                                       'TP': dense_tp })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "c579d701-92ae-42b1-fa30-eb99bde4143e",
        "id": "PiIP4KcMiyWL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "models_acc = models_acc.append(models_acc_dense_model)\n",
        "models_acc"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FN</th>\n",
              "      <th>FP</th>\n",
              "      <th>TN</th>\n",
              "      <th>TP</th>\n",
              "      <th>acc_on_test</th>\n",
              "      <th>acc_on_val</th>\n",
              "      <th>cross_val_score_mean_test</th>\n",
              "      <th>cross_val_score_mean_val</th>\n",
              "      <th>model_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360</td>\n",
              "      <td>456</td>\n",
              "      <td>3249</td>\n",
              "      <td>3435</td>\n",
              "      <td>0.87648</td>\n",
              "      <td>0.891200</td>\n",
              "      <td>0.88224</td>\n",
              "      <td>0.876933</td>\n",
              "      <td>log_regr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>462</td>\n",
              "      <td>424</td>\n",
              "      <td>3281</td>\n",
              "      <td>3333</td>\n",
              "      <td>0.87264</td>\n",
              "      <td>0.881867</td>\n",
              "      <td>0.87508</td>\n",
              "      <td>0.882000</td>\n",
              "      <td>d2v</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>785</td>\n",
              "      <td>892</td>\n",
              "      <td>2813</td>\n",
              "      <td>3010</td>\n",
              "      <td>0.77196</td>\n",
              "      <td>0.776400</td>\n",
              "      <td>0.77148</td>\n",
              "      <td>0.780667</td>\n",
              "      <td>pol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>444</td>\n",
              "      <td>431</td>\n",
              "      <td>3274</td>\n",
              "      <td>3351</td>\n",
              "      <td>0.87504</td>\n",
              "      <td>0.883333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>dense_model</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    FN   FP    TN    TP  acc_on_test  acc_on_val  cross_val_score_mean_test  \\\n",
              "0  360  456  3249  3435      0.87648    0.891200                    0.88224   \n",
              "0  462  424  3281  3333      0.87264    0.881867                    0.87508   \n",
              "0  785  892  2813  3010      0.77196    0.776400                    0.77148   \n",
              "0  444  431  3274  3351      0.87504    0.883333                        NaN   \n",
              "\n",
              "   cross_val_score_mean_val   model_name  \n",
              "0                  0.876933     log_regr  \n",
              "0                  0.882000          d2v  \n",
              "0                  0.780667          pol  \n",
              "0                       NaN  dense_model  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "0BluLkAemIgi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save the trained model on Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "USO-M_a5mHtf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_list = [NN_MODEL_PATH[\"DENSE_MODEL\"]]\n",
        "\n",
        "upload_to_GD(file_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f7zNK9N-397R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural network model 2"
      ]
    },
    {
      "metadata": {
        "id": "kGOgd5t64Brq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This neural netowrk is a convolutional neural network (CNN). The text review should be converted to numeric format when each word from the text is replaced with its numeric code. Words that are not in the dictionary, are thrown away."
      ]
    },
    {
      "metadata": {
        "id": "WySYp6IDqtaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "118df578-ba27-4e25-ee60-2ecf4754df47"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# create numeric representation of input data\n",
        "X_train_numbers = nn_data_prepare.set_to_numbers(X_train_tok)\n",
        "X_val_numbers = nn_data_prepare.set_to_numbers(X_val_tok)\n",
        "X_test_numbers = nn_data_prepare.set_to_numbers(X_test_tok)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 59min 7s, sys: 10.4 s, total: 59min 18s\n",
            "Wall time: 59min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5FwnmWw46tXf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Sequences that are fed in CNN should have the same length. Let's check length of the resulting numeric representations for the training set."
      ]
    },
    {
      "metadata": {
        "id": "oEgHX2G4sxsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "0f136a79-77c9-4d8e-95fd-b232893f35ff"
      },
      "cell_type": "code",
      "source": [
        "X_train_len = np.asarray([len(x) for x in X_train_numbers])\n",
        "print \"Mean \", np.mean(X_train_len) \n",
        "print \"std \", np.std(X_train_len)\n",
        "\n",
        "sns.boxplot(X_train_len)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean  109.29611428571428\n",
            "std  79.95513939910177\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f92c754e8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFKCAYAAACQMm9DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAsEEgALBBICC/wMYqNTEKo6FlgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3I0UiUeH6VA5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the plot above it follows that almost all numeric representations of reviews has less than 500 elements. So let's pad all sequences to the length of 500."
      ]
    },
    {
      "metadata": {
        "id": "CAB_Y9ynPLzJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAXLEN = 500\n",
        "# get padded sequences\n",
        "X_train_padded = nn_data_prepare.padded_set(X_train_numbers, maxlen=MAXLEN)\n",
        "X_val_padded = nn_data_prepare.padded_set(X_val_numbers, maxlen=MAXLEN)\n",
        "X_test_padded = nn_data_prepare.padded_set(X_test_numbers, maxlen=MAXLEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tSJEB0gDPPpp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create cnn model"
      ]
    },
    {
      "metadata": {
        "id": "4YuLrkzrPL7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "1827892c-20f3-42c7-db57-053097edd741"
      },
      "cell_type": "code",
      "source": [
        "cnn_model = nn_model.cnn_model()\n",
        "cnn_model.summary()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 500, 100)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 499, 100)          20100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 249, 100)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 24900)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 250)               6225250   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 7,245,601\n",
            "Trainable params: 7,245,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CswHLYESu4LT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fit the model"
      ]
    },
    {
      "metadata": {
        "id": "s2QbvRIGPMDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "d3033374-5881-4fba-8f5c-de19832e74a4"
      },
      "cell_type": "code",
      "source": [
        "nn_train = NN_Train_Predict()\n",
        "hist = nn_train.compile_and_fit_model(cnn_model, X_train_padded, train_labels, X_val_padded, val_labels, path_to_save=NN_MODEL_PATH[\"CNN_MODEL\"])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17500 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "17500/17500 [==============================] - 17s 953us/step - loss: 0.4081 - binary_accuracy: 0.7890 - val_loss: 0.3443 - val_binary_accuracy: 0.8608\n",
            "Epoch 2/20\n",
            "17500/17500 [==============================] - 12s 658us/step - loss: 0.1932 - binary_accuracy: 0.9261 - val_loss: 0.2912 - val_binary_accuracy: 0.8861\n",
            "Epoch 3/20\n",
            "17500/17500 [==============================] - 12s 659us/step - loss: 0.0981 - binary_accuracy: 0.9658 - val_loss: 0.3635 - val_binary_accuracy: 0.8725\n",
            "Epoch 4/20\n",
            "17500/17500 [==============================] - 12s 659us/step - loss: 0.0439 - binary_accuracy: 0.9851 - val_loss: 0.5270 - val_binary_accuracy: 0.8741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uGV0yF72u-mq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "gk3KPjNBvEI8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "d8cc0352-eb32-40d9-ea17-1eea98bc594e"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "cnn_model = load_model(NN_MODEL_PATH[\"CNN_MODEL\"])\n",
        "cnn_loss_val, cnn_acc_val = nn_train.model_evaluate(cnn_model, X_val_padded, val_labels)\n",
        "print \"Validation set. loss: \", cnn_loss_val, \", accuracy: \", cnn_acc_val \n",
        "cnn_loss_test, cnn_acc_test = nn_train.model_evaluate(cnn_model, X_test_padded, test_labels)\n",
        "print \"Test set. loss: \", cnn_loss_test, \", accuracy: \", cnn_acc_test "
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7500/7500 [==============================] - 1s 165us/step\n",
            "Validation set. loss:  0.2912138703107834 , accuracy:  0.8861333333333333\n",
            "25000/25000 [==============================] - 3s 132us/step\n",
            "Test set. loss:  0.3260982282781601 , accuracy:  0.8642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7CA1EN9bvgli",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "sHy-g66vv8kD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get predicted class labels\n",
        "cnn_predicted_classes = nn_train.model_predict_classes(cnn_model, X_val_padded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dXjJ9OlBvsvQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d63a937d-25e7-44ff-ffc1-fa6136e46fbc"
      },
      "cell_type": "code",
      "source": [
        "cnn_tn, cnn_fp, cnn_fn, cnn_tp = confusion_matrix(val_labels, cnn_predicted_classes.flatten()).ravel()\n",
        "print cnn_tn, cnn_fp, cnn_fn, cnn_tp"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3354 351 503 3292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0ksGmT97wOdt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save result of evaluation"
      ]
    },
    {
      "metadata": {
        "id": "Hh1jUB3mwTVi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models_acc_cnn_model = pd.DataFrame({'model_name': [\"cnn_model\"], \n",
        "                                     'acc_on_val': cnn_acc_val, \\\n",
        "                                     'cross_val_score_mean_val': None, \\\n",
        "                                     'acc_on_test': cnn_acc_test, \n",
        "                                     'cross_val_score_mean_test': None,\n",
        "                                     'TN': cnn_tn,\n",
        "                                     'FP': cnn_fp,\n",
        "                                     'FN': cnn_fn,\n",
        "                                     'TP': cnn_tp })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "woIeFdSWw4La",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d6ab7d79-5c69-4618-c629-817c5bb1d40b"
      },
      "cell_type": "code",
      "source": [
        "models_acc = models_acc.append(models_acc_cnn_model)\n",
        "models_acc"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FN</th>\n",
              "      <th>FP</th>\n",
              "      <th>TN</th>\n",
              "      <th>TP</th>\n",
              "      <th>acc_on_test</th>\n",
              "      <th>acc_on_val</th>\n",
              "      <th>cross_val_score_mean_test</th>\n",
              "      <th>cross_val_score_mean_val</th>\n",
              "      <th>model_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360</td>\n",
              "      <td>456</td>\n",
              "      <td>3249</td>\n",
              "      <td>3435</td>\n",
              "      <td>0.87648</td>\n",
              "      <td>0.891200</td>\n",
              "      <td>0.88224</td>\n",
              "      <td>0.876933</td>\n",
              "      <td>log_regr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>462</td>\n",
              "      <td>424</td>\n",
              "      <td>3281</td>\n",
              "      <td>3333</td>\n",
              "      <td>0.87264</td>\n",
              "      <td>0.881867</td>\n",
              "      <td>0.87508</td>\n",
              "      <td>0.882000</td>\n",
              "      <td>d2v</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>785</td>\n",
              "      <td>892</td>\n",
              "      <td>2813</td>\n",
              "      <td>3010</td>\n",
              "      <td>0.77196</td>\n",
              "      <td>0.776400</td>\n",
              "      <td>0.77148</td>\n",
              "      <td>0.780667</td>\n",
              "      <td>pol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>444</td>\n",
              "      <td>431</td>\n",
              "      <td>3274</td>\n",
              "      <td>3351</td>\n",
              "      <td>0.87504</td>\n",
              "      <td>0.883333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>dense_model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>503</td>\n",
              "      <td>351</td>\n",
              "      <td>3354</td>\n",
              "      <td>3292</td>\n",
              "      <td>0.86420</td>\n",
              "      <td>0.886133</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cnn_model</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    FN   FP    TN    TP  acc_on_test  acc_on_val  cross_val_score_mean_test  \\\n",
              "0  360  456  3249  3435      0.87648    0.891200                    0.88224   \n",
              "0  462  424  3281  3333      0.87264    0.881867                    0.87508   \n",
              "0  785  892  2813  3010      0.77196    0.776400                    0.77148   \n",
              "0  444  431  3274  3351      0.87504    0.883333                        NaN   \n",
              "0  503  351  3354  3292      0.86420    0.886133                        NaN   \n",
              "\n",
              "   cross_val_score_mean_val   model_name  \n",
              "0                  0.876933     log_regr  \n",
              "0                  0.882000          d2v  \n",
              "0                  0.780667          pol  \n",
              "0                       NaN  dense_model  \n",
              "0                       NaN    cnn_model  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "H3Ybdt_9mQni",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save trained model on Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "wdrABrF7PMBH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# save model on Google drive\n",
        "file_list = [NN_MODEL_PATH[\"CNN_MODEL\"]]\n",
        "upload_to_GD(file_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zyK2QUA3eIKM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ]
    },
    {
      "metadata": {
        "id": "jE5utiGneSZ2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The table below includes the collected info about the constructed models."
      ]
    },
    {
      "metadata": {
        "id": "DdBEUmeUWuKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "77fc9f9b-3cb8-4eb9-e141-b62d81737459"
      },
      "cell_type": "code",
      "source": [
        "models_acc\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FN</th>\n",
              "      <th>FP</th>\n",
              "      <th>TN</th>\n",
              "      <th>TP</th>\n",
              "      <th>acc_on_test</th>\n",
              "      <th>acc_on_val</th>\n",
              "      <th>cross_val_score_mean_test</th>\n",
              "      <th>cross_val_score_mean_val</th>\n",
              "      <th>model_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360</td>\n",
              "      <td>456</td>\n",
              "      <td>3249</td>\n",
              "      <td>3435</td>\n",
              "      <td>0.87648</td>\n",
              "      <td>0.891200</td>\n",
              "      <td>0.88224</td>\n",
              "      <td>0.876933</td>\n",
              "      <td>log_regr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>462</td>\n",
              "      <td>424</td>\n",
              "      <td>3281</td>\n",
              "      <td>3333</td>\n",
              "      <td>0.87264</td>\n",
              "      <td>0.881867</td>\n",
              "      <td>0.87508</td>\n",
              "      <td>0.882000</td>\n",
              "      <td>d2v</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>785</td>\n",
              "      <td>892</td>\n",
              "      <td>2813</td>\n",
              "      <td>3010</td>\n",
              "      <td>0.77196</td>\n",
              "      <td>0.776400</td>\n",
              "      <td>0.77148</td>\n",
              "      <td>0.780667</td>\n",
              "      <td>pol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>444</td>\n",
              "      <td>431</td>\n",
              "      <td>3274</td>\n",
              "      <td>3351</td>\n",
              "      <td>0.87504</td>\n",
              "      <td>0.883333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>dense_model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>503</td>\n",
              "      <td>351</td>\n",
              "      <td>3354</td>\n",
              "      <td>3292</td>\n",
              "      <td>0.86420</td>\n",
              "      <td>0.886133</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cnn_model</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    FN   FP    TN    TP  acc_on_test  acc_on_val  cross_val_score_mean_test  \\\n",
              "0  360  456  3249  3435      0.87648    0.891200                    0.88224   \n",
              "0  462  424  3281  3333      0.87264    0.881867                    0.87508   \n",
              "0  785  892  2813  3010      0.77196    0.776400                    0.77148   \n",
              "0  444  431  3274  3351      0.87504    0.883333                        NaN   \n",
              "0  503  351  3354  3292      0.86420    0.886133                        NaN   \n",
              "\n",
              "   cross_val_score_mean_val   model_name  \n",
              "0                  0.876933     log_regr  \n",
              "0                  0.882000          d2v  \n",
              "0                  0.780667          pol  \n",
              "0                       NaN  dense_model  \n",
              "0                       NaN    cnn_model  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "029iduy-l12o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's rename and rearrange the columns and reset the index."
      ]
    },
    {
      "metadata": {
        "id": "heKVhjw1iieN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "45706bda-3ff7-487c-8537-48f213c7dcd5"
      },
      "cell_type": "code",
      "source": [
        "models_acc = models_acc[[\"model_name\", 'acc_on_val', 'cross_val_score_mean_val', 'TN', 'FP', 'FN', 'TP', 'acc_on_test', 'cross_val_score_mean_test']]\n",
        "models_acc.rename(index=str, columns={\"TN\": \"TN_val\", \"FP\": \"FP_val\", \"FN\": \"FN_val\", \"TP\": \"TP_val\"}, inplace=True)\n",
        "models_acc.reset_index(inplace=True, drop=True)\n",
        "models_acc"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>acc_on_val</th>\n",
              "      <th>cross_val_score_mean_val</th>\n",
              "      <th>TN_val</th>\n",
              "      <th>FP_val</th>\n",
              "      <th>FN_val</th>\n",
              "      <th>TP_val</th>\n",
              "      <th>acc_on_test</th>\n",
              "      <th>cross_val_score_mean_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_regr</td>\n",
              "      <td>0.891200</td>\n",
              "      <td>0.876933</td>\n",
              "      <td>3249</td>\n",
              "      <td>456</td>\n",
              "      <td>360</td>\n",
              "      <td>3435</td>\n",
              "      <td>0.87648</td>\n",
              "      <td>0.88224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d2v</td>\n",
              "      <td>0.881867</td>\n",
              "      <td>0.882000</td>\n",
              "      <td>3281</td>\n",
              "      <td>424</td>\n",
              "      <td>462</td>\n",
              "      <td>3333</td>\n",
              "      <td>0.87264</td>\n",
              "      <td>0.87508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pol</td>\n",
              "      <td>0.776400</td>\n",
              "      <td>0.780667</td>\n",
              "      <td>2813</td>\n",
              "      <td>892</td>\n",
              "      <td>785</td>\n",
              "      <td>3010</td>\n",
              "      <td>0.77196</td>\n",
              "      <td>0.77148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dense_model</td>\n",
              "      <td>0.883333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3274</td>\n",
              "      <td>431</td>\n",
              "      <td>444</td>\n",
              "      <td>3351</td>\n",
              "      <td>0.87504</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cnn_model</td>\n",
              "      <td>0.886133</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3354</td>\n",
              "      <td>351</td>\n",
              "      <td>503</td>\n",
              "      <td>3292</td>\n",
              "      <td>0.86420</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    model_name  acc_on_val  cross_val_score_mean_val  TN_val  FP_val  FN_val  \\\n",
              "0     log_regr    0.891200                  0.876933    3249     456     360   \n",
              "1          d2v    0.881867                  0.882000    3281     424     462   \n",
              "2          pol    0.776400                  0.780667    2813     892     785   \n",
              "3  dense_model    0.883333                       NaN    3274     431     444   \n",
              "4    cnn_model    0.886133                       NaN    3354     351     503   \n",
              "\n",
              "   TP_val  acc_on_test  cross_val_score_mean_test  \n",
              "0    3435      0.87648                    0.88224  \n",
              "1    3333      0.87264                    0.87508  \n",
              "2    3010      0.77196                    0.77148  \n",
              "3    3351      0.87504                        NaN  \n",
              "4    3292      0.86420                        NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "Wj3-tZ9LmOGB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The meaning of the columns in the table above is the following:\n",
        "\n",
        "*   *model_name*:  name of the model\n",
        "*   *acc_on_val*: accuracy on the validation set\n",
        "*  *cross_val_score_mean_val*:  accuracy by cross validation calculated on the validation set\n",
        "*   *TN_val*: number of true negatives calculated on the validation set\n",
        "*   *FP_val*: number of false positives calculated on the validation set\n",
        "*   *FN_val*: number of false negatives calculated on the validation set\n",
        "*   *TP_val*: number of true positives calculated on the validation set\n",
        "*   *acc_on_test*: accuracy on the test set\n",
        "*   *cross_val_score_mean_test*: accuracy by cross validation calculated on the test set.\n",
        "\n",
        "For neural network models \"*dense_model*\"  and \"*cnn_model*\" accuracy by cross validation has not been calculated yet and thet's why there are NaNs in the corresponding rows of the table.\n",
        "\n",
        "\"*pol*\" model based on the polarity analysis from TextBlob library is the worst model and cannot be recommended for further use.\n",
        "\n",
        "Accuracies of other four models (\"*log_regr*\", \"*d2v*\", \"*dense_model*\", \"*cnn_model*\") calculated on the both validated and test sets are very close. For \"*log_regr*\" and \"*d2v*\" models, accuracy calculated on the whole validation / test set is close to accuracy by cross validation. It follows that \"*log_regr*\", \"*d2v*\", \"*dense_model*\", \"*cnn_model*\" models are rather stable and possess similar characteristics. \n",
        "\n",
        "To make the final decision on the model to be recommended for use in the production, the additional analysis is required (for more details see the following section Further steps). The final decision should also take into account the cost of making a Type I and Type II errors and other requirements (model response time, model complexity, etc).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wYNWXwZY_TrS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Further steps "
      ]
    },
    {
      "metadata": {
        "id": "yi73n5Xh_lzs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To further investigate properties of the models constructed above, the following steps are proposed:\n",
        "1.   calculate accuracy by cross validation for neural network models \"*dense_model*\" and \"*cnn_model*\"\n",
        "2.   analyze examples on which the models fail. It may help to improve preprocessing to avoid classification errors\n",
        "3.   tune hyperparameters of neural network models (number of the hidden layers, number of neurons per layer, learning rate, etc) with e.g. *hyperopt* library\n",
        "4.   check if removing stopwords really improves the model quality. It may turn out that the model constructed on data with stopwords yields better accuracy\n",
        "5. check if dictionary size influence strongly the model quality.\n",
        "\n",
        "As \"*log_regr*\", \"*d2v*\", \"*dense_model*\", \"*cnn_model*\" models work with different features generated on the basis of the raw review texts, it is reasonable to consider voting ensemble classifier based on hard or soft voting (soft voting is when class labels are predicted based on probabilities predicted by base classifiers; hard voting is a majority-based voting). The voting classifier may have significantly better accuracy in comparison with the base classifiers.\n",
        "\n",
        " \"*dense_model*\" and \"*cnn_model*\" neural network models are based only on 1-grams. To take into account 2- and 3-, etc-grams presented in the text, another neural network model can be created. As input, this model will take padded sequences. Each sequence consists of dictionary indexes of 1- and 2-, etc-grams that present in the text. Stated another way,  words in the initial review text is replaced with their indexes from the dictionary. The resulted sequence is extended with indexes of 2-, 3-, etc-grams from the dictionary and then padded to the predefined length. I assume that a dense network with 2-3 hidden layers can be used. \n",
        "\n",
        "\n",
        "\n",
        "Model analysis, ensembling and construction of the additional neural network model based on 1-, 2-, etc-grams described above require additional time and efforts and that's why are not performed here.\n"
      ]
    }
  ]
}