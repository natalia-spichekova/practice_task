{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sent_analysis_report.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_vimrndrxHbC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check envinroment"
      ]
    },
    {
      "metadata": {
        "id": "hP4GCKnYxPCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "541d7b53-d9a2-4843-fd75-8386786eabc3"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print sys.version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.7.15rc1 (default, Nov 12 2018, 14:31:15) \n",
            "[GCC 7.3.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iuM8Z_XBl9M3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Set up Colab"
      ]
    },
    {
      "metadata": {
        "id": "Mjy85BwimWb8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook was prepared in Colab. To load data and python scripts in Colab, some additional steps are to be performed. \n",
        "First, data archive and python scripts archive were uploaded in Google Drive and shared for public access.\n",
        "Then files were downloaded to Colab from Google Drive by means of the link. At last, the uploaded archives were extracted.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "y-nL0mtymF5V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "021f6433-236a-42e6-9b8a-45a9e9f36081"
      },
      "cell_type": "code",
      "source": [
        "# install pydrive to load daa and script files \n",
        "!pip install pydrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python2.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python2.7/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python2.7/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive) (0.11.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.4)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive) (1.11.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RlzX1LotwMBI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import tarfile\n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2vDMsQyHEJbO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2clPBWSby5pA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load and exctract data files in Colab\n",
        "\n",
        "# shared link to data archive file\n",
        "# https://drive.google.com/open?id=1iqg3npFMm-7EeqDbZbwOHJbms01lAjbC \n",
        "\n",
        "download = drive.CreateFile({'id': '1iqg3npFMm-7EeqDbZbwOHJbms01lAjbC'})\n",
        "download.GetContentFile('aclImdb_v1.tar.gz')\n",
        "\n",
        "# unzip\n",
        "if not os.path.exists('data'):\n",
        "  os.makedirs(\"data\")\n",
        "\n",
        "tar = tarfile.open('aclImdb_v1.tar.gz', \"r:gz\")\n",
        "tar.extractall('data/')\n",
        "tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ospR4rXU_Qec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load and extract python scripts\n",
        "\n",
        "# shared link to script files\n",
        "# https://drive.google.com/open?id=1_bpTo5grQVfOd9DuXSBxmPGVkve_XVTc\n",
        "\n",
        "download_scr = drive.CreateFile({'id': '1_bpTo5grQVfOd9DuXSBxmPGVkve_XVTc'})\n",
        "download_scr.GetContentFile('scripts.zip')\n",
        "\n",
        "zip_ref = zipfile.ZipFile('scripts.zip', \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JbhA8iq56OUN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset description"
      ]
    },
    {
      "metadata": {
        "id": "kUF7_hmO6VcD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The dataset, that is used to create the model, is a Large Movie Review Dataset v1.0. The dataset along with its description is available at http://ai.stanford.edu/~amaas/data/sentiment/\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Vr893qgYp4BD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ]
    },
    {
      "metadata": {
        "id": "EECprqdXqEo0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Read raw text data."
      ]
    },
    {
      "metadata": {
        "id": "_O5n9A-fqTec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import utils\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eh22syFF-46V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "\n",
        "train_path = os.path.join(\"data\", \"aclImdb\", \"train\")\n",
        "test_path = os.path.join(\"data\", \"aclImdb\", \"test\")\n",
        "\n",
        "train = utils.loaddata(train_path)\n",
        "test = utils.loaddata(test_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZH-yWJF3htOV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "ef9fd1f7-e79a-4873-e00c-1b65d73f7d72"
      },
      "cell_type": "code",
      "source": [
        "print train[1][0], train[0][0]\n",
        "print train[1][12500], train[0][12500]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n",
            "1 Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UsENUWrZsuo-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Split train data into two subsets - train data and validation data in the proportion 70:30. Validation data We'll train models on the train subset and check model accuracy on the validation subset. Quality of the final model will be checked on test subset."
      ]
    },
    {
      "metadata": {
        "id": "mS9aECuSBYmd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split train set into train and validation \n",
        "train_data, val_data, train_target, val_target = train_test_split(train[0], train[1], shuffle=True, test_size=0.3, random_state=123)\n",
        "\n",
        "test_data = test[0]\n",
        "test_target = test[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OfwE_djF79Om",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "4e3b124c-0bb6-4111-c530-7018c365dedd"
      },
      "cell_type": "code",
      "source": [
        "train_data[0:3]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[u'I created my own reality by walking out of the theater I was roped in by my girlfriend into going to this dreck with her mom. We (my g-friend and I) walked out about an hour into it. What a load of pseudo scientific new age jargon.<br /><br />Sub atomic particles are thoughts? By taping labels to bottles of water and blessing it by a Buddhist monk it grew little pretty crystals? A drop of 25% in the murder rate in DC happened when a bunch of folks meditated. Wow, what a rigorous scientific study. I\\'m sure that someone ate cheerios for four days straight during the same time. Should we conclude that eating cheerios caused a drop in the murder rate? <br /><br />Hogwash, hooey, bull pucky! <br /><br />BTW- It was funded by the Ramtha cult, the leader of which was one of the \"experts\" which were interview by the filmmakers. No ulterior motives here, right?',\n",
              " u'The most horrible retelling of a great series. It should not have been named Battlestar Galactica, because it\\'s only the same in name alone. Too many changes to just have changes. You have characters turned from male to female, black to asian to cylon all in a way to \"attract female audiences,\" when there was already strong female characters that could have just been made stronger. Gone are the egyptian feeling. Gone are the quest for earth. The lack of cylons to go to terminator rejects takes away from the film, especially when one is made a fembot. Granted the original show had a lot of cheese to it, but it had a large following. They tried to hold onto this following but give the fans nothing to work with and basically spit in their face as they make it \"their own story.\" Changes are good, when they make something better, not to just make them.',\n",
              " u\"***SPOILERS*** ***SPOILERS*** Packed with memorable moments (such as the quote above, immortalized by Primus), Deliverance tells the story of four guys who take a trip to the wild woods to go white water rafting and get away from the big city for a while only to find that their fun soon takes a bad turn. This is not a Hollywood film. There are virtually no special effects whatsoever, the setting is extremely realistic, and nothing at all is sugarcoated or made pretty. The city boys look like city boys, and even the tough guy Louis, portrayed with precision by Burt Reynolds, is clearly at the mercy of the wild on this trip. This is a perfect example of a what-if film. What if a few friends went river rafting in an area of the woods that none of them were familiar with, and ended up desperately trying to avoid being tried and convicted for murders that they were forced to commit to save their own lives?<br /><br />There is clearly a very strong element of the film that deals with societal and class structure and the relationship (or lack thereof) between rural and urban peoples. When the four guys arrive in the woods early in the film, they clearly do not quite know how to interact with the people who live out there, and they speak to them as though they are unsure whether they will understand or be able to communicate. This communication block is most memorably illustrated in the dueling banjoes scene, in which they are trying to gas up the car and truck and get someone to drive the vehicles downriver for them. While Drew and the obviously inbred and probably mentally deficient boy on the porch are dueling with their guitar and banjo (one of the best scenes in the film), Louis is having some difficulty buying the gas, and Bobby makes a comment about genetic deficiencies and how pathetic it all is. When the boy turns away from Drew, who had offered to shake his hand after their stupendous jam session, Bobby tells him to give the kid a couple bucks, knowing that none of them are quite sure how to react.<br /><br />This is the kind of thing that we see in Deliverance that sets up so much of the tension that is to follow. This great scene where a lot of fun was had (including the funniest 'redneck dancing' scene until O Brother, Where Art Thou?) ended with everyone awkwardly unsure what to do around each other. These people are apples and oranges, and they live by completely different rules of life. The people that Louis, Bobby, Drew and Ed encounter in the hills grew up separated from modern society and modern laws, and live by the rules of nature, which do not include thou shalt not kill. Confused by their awkward behavior, the four friends set out on the river, hoping for the weirdness to end and for the adventure to begin.<br /><br />(spoilers) When they are briefly separated from each other and Ed and Bobby run into the hillbillies beside the river who quickly turn unpleasant, the uncertainty about the way that these people live - which was established by the scene above - comes into play to create the most tension during the scene. I think that a good sign of a quality thriller like this is that the tragic element of the film, namely the assaults and actual murders, takes up a very small amount of screen time but remain some of the most memorable parts of the film. There is no gratuitous violence here, it's all there for an obvious purpose and it achieves a startlingly powerful effect.<br /><br />The move is about the violent clash of two very different kinds of people, and what can happen when they inadvertently find themselves at war with each other. The trip down the rest of the river after the assault, which takes up the majority of the film, delivers some spectacularly effective tension, and keeps you on the edge of your seat while not bombarding you with so much happening that you become numb. It is surprisingly effective when we find out that Ed may very well have killed the wrong man up there on the cliff, and the tension in the film doesn't even let up when the three surviving members of the team reach the bottom of the river, because they deliver a questionable explanation to the police about what happened up there on the river and why the deputy's brother-in-law is missing.<br /><br />This is a very disturbing film, which is a testament to its success, because it's pretty obvious that a film like this is meant to shake people up a little bit. The hillbillies are the human (i.e. more realistic) version of the sub-human rednecks seen in childish but fairly similar films like Gator Bait and Gator Bait 2, neither of which could possibly ever be compared to a timeless film like Deliverance. When we follow these four men through their fateful weekend in the woods, the natural element is so real and we get to know the men so well and in such a subtle fashion that it's almost like we, as individuals of the audience, are really a fifth member of the team. It's not often that a film is able to come across that way.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "mFqxtCpW21ag",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Preprocess data"
      ]
    },
    {
      "metadata": {
        "id": "PpCz2DoO2-_M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following rules are applied during preprocessing:\n",
        "\n",
        "1. characters are  converted to lowercase \n",
        "2. contracted forms are replaced with the corresponding full forms\n",
        "3. some special characters like (), {}, !,, etc are replaced with space\n",
        "4. characters that are not digits, letters, space, underscore or \"#\", \"+\" are removed\n",
        "5. stopwords are removed.\n",
        "\n",
        "To filter stopwords, stopwords corpus from nltk python package is used. Words 'no', 'nor', 'not' are assumed to be important for sentiment analysis and are excluded from the stopwords corpus.\n",
        "\n",
        "Patterns to be replaced are defined with regular expressions. More details on the replacement rules can be found in \"process.py\" file.\n"
      ]
    },
    {
      "metadata": {
        "id": "ZNdyWTldBlsS",
        "colab_type": "code",
        "outputId": "9acd404c-c7c5-4205-ea63-ed1835d1759e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "from preprocess import TextPreprocessor"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tq3Bz2UG2543",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5311f4d5-4df3-4a98-ec5f-f3877270c0cb"
      },
      "cell_type": "code",
      "source": [
        "# preprocess data\n",
        "prp = TextPreprocessor()\n",
        "\n",
        "X_train_tok = [prp.clean_text(text) for text in train_data]\n",
        "print('train subset is preprocessed')\n",
        "X_val_tok = [prp.clean_text(text) for text in val_data]\n",
        "print('validation subset is preprocessed')\n",
        "X_test_tok = [prp.clean_text(text) for text in test_data]\n",
        "print('test subset is preprocessed')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train subset is preprocessed\n",
            "validation subset is preprocessed\n",
            "test subset is preprocessed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qo7ZQKRJ_xxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "0899a0e7-6b3e-4805-93f4-8475f1a96028"
      },
      "cell_type": "code",
      "source": [
        "# example of the preproccessed text\n",
        "X_train_tok[0:3]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[u'created reality walking theater roped girlfriend going dreck mom g friend walked hour load pseudo scientific new age jargon sub atomic particles thoughts taping labels bottles water blessing buddhist monk grew little pretty crystals drop 25 murder rate dc happened bunch folks meditated wow rigorous scientific study sure someone ate cheerios four days straight time conclude eating cheerios caused drop murder rate hogwash hooey bull pucky btw funded ramtha cult leader one experts interview filmmakers no ulterior motives right',\n",
              " u'horrible retelling great series not named battlestar galactica name alone many changes changes characters turned male female black asian cylon way attract female audiences already strong female characters could made stronger gone egyptian feeling gone quest earth lack cylons go terminator rejects takes away film especially one made fembot granted original show lot cheese large following tried hold onto following give fans nothing work basically spit face make story changes good make something better not make',\n",
              " u'spoilers spoilers packed memorable moments quote immortalized primus deliverance tells story four guys take trip wild woods go white water rafting get away big city find fun soon takes bad turn not hollywood film virtually no special effects whatsoever setting extremely realistic nothing sugarcoated made pretty city boys look like city boys even tough guy louis portrayed precision burt reynolds clearly mercy wild trip perfect example film friends went river rafting area woods none familiar ended desperately trying avoid tried convicted murders forced commit save lives clearly strong element film deals societal class structure relationship lack thereof rural urban peoples four guys arrive woods early film clearly not quite know interact people live speak though unsure whether understand able communicate communication block memorably illustrated dueling banjoes scene trying gas car truck get someone drive vehicles downriver drew obviously inbred probably mentally deficient boy porch dueling guitar banjo one best scenes film louis difficulty buying gas bobby makes comment genetic deficiencies pathetic boy turns away drew offered shake hand stupendous jam session bobby tells give kid couple bucks knowing none quite sure react kind thing see deliverance sets much tension follow great scene lot fun including funniest redneck dancing scene brother art thou ended everyone awkwardly unsure around people apples oranges live completely different rules life people louis bobby drew ed encounter hills grew separated modern society modern laws live rules nature not include thou shalt not kill confused awkward behavior four friends set river hoping weirdness end adventure begin spoilers briefly separated ed bobby run hillbillies beside river quickly turn unpleasant uncertainty way people live established scene comes play create tension scene think good sign quality thriller like tragic element film namely assaults actual murders takes small amount screen time remain memorable parts film no gratuitous violence obvious purpose achieves startlingly powerful effect move violent clash two different kinds people happen inadvertently find war trip rest river assault takes majority film delivers spectacularly effective tension keeps edge seat not bombarding much happening become numb surprisingly effective find ed may well killed wrong man cliff tension film not even let three surviving members team reach bottom river deliver questionable explanation police happened river deputy brother law missing disturbing film testament success pretty obvious film like meant shake people little bit hillbillies human e realistic version sub human rednecks seen childish fairly similar films like gator bait gator bait 2 neither could possibly ever compared timeless film like deliverance follow four men fateful weekend woods natural element real get know men well subtle fashion almost like individuals audience really fifth member team not often film able come across way']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "eK1JuXd7iGG-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's check what is length of review texts. We'll do calculations for train dataset."
      ]
    },
    {
      "metadata": {
        "id": "qSjzY76fiFYG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "c50abc18-11a3-40c3-a05c-5d6f7b51ebb0"
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns \n",
        "import numpy as np\n",
        "\n",
        "review_len = [len(text) for text in X_train_tok]\n",
        "print \"Mean \", np.mean(review_len) \n",
        "print \"std \", np.std(review_len)\n",
        "\n",
        "sns.boxplot(review_len)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Mean  838.9772571428572\n",
            "std  643.7283114992067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/seaborn/categorical.py:454: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
            "  box_data = remove_na(group_data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd276fc67d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdYAAAFKCAYAAACgvn5iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4OhJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4P2_iqCmjwti",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the plot above it follows that the 75th percentile approximately equals to 1000. It means that 75% of lengths of review texts in X_train_tok set is below 1000. "
      ]
    },
    {
      "metadata": {
        "id": "L_OeAxQV_cIM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Approach based on logistic regression"
      ]
    },
    {
      "metadata": {
        "id": "voEDdAJ75qVG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The idea is to create tf-idf features for documents (i.e reviews) and apply logistic regression algorithm to a matrix of tf-idf features. Instead of tf-idf, bag-of-words approach can be used to generate document features. Tf-idf approach was selected because usually it provides better results. "
      ]
    },
    {
      "metadata": {
        "id": "aCvXFfk_DqHb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When creating a matrix with tf-idf features for sentiment analysis, it is reasonable to take into account both 1-and 2- grams. Let's check number of ngrams and their frequency in the corpus:"
      ]
    },
    {
      "metadata": {
        "id": "NIy7LpFPDSxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cbff99ec-cc56-4dd6-b3b5-da1eb72655ba"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cnt_vect = CountVectorizer(ngram_range=(1, 2), max_df=0.9, min_df=5)\n",
        "bag_of_words = cnt_vect.fit_transform(X_train_tok)\n",
        "\n",
        "print \"Total number of ngrams: \", bag_of_words.shape[1]\n",
        "\n",
        "# ngrams in the corpus\n",
        "sum_words = bag_of_words.toarray().sum(axis=0)\n",
        "\n",
        "# ngrams and their frequencies in the corpus\n",
        "ngrams_dict = {word: freq for word, freq in zip(cnt_vect.get_feature_names(), sum_words)}\n",
        "# sort ngrams by the frequency in reverse order\n",
        "ngrams_dict_sorted = sorted(ngrams_dict.items(), key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of ngrams:  65821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2amRoL-WMWMg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "8f01ac53-49f1-412d-fc14-62afa88c0d5f"
      },
      "cell_type": "code",
      "source": [
        "N = 12000\n",
        "ngrams_dict_sorted[N:][0:5]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(u'gets better', 28),\n",
              " (u'cracker', 28),\n",
              " (u'tin', 28),\n",
              " (u'matter much', 28),\n",
              " (u'gusto', 28)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "YYkZ-2qZQEE3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Top of N=12000 ngrams has frequency higher than 30. Other ngrams are  less frequent.  It seems rather reasonable to preserve a top of N=12000 ngrams in the dictionary. "
      ]
    },
    {
      "metadata": {
        "id": "Vi9_O2MUSIkH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create tf-idf features :"
      ]
    },
    {
      "metadata": {
        "id": "zCkJkbVUEzj_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from models import Model\n",
        "\n",
        "m = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cOMmmH6xUmPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a1fc4cb3-5153-4a7d-b76f-f5e3f7298de9"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# get tfidt features\n",
        "X_train_tfidf_tok, tfidf_vect = m.tfidf_train(X_train_tok, ngram_range=(1,2), max_df=0.9, \n",
        "                                       min_df=5, max_features=12000)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 22.5 s, sys: 391 ms, total: 22.9 s\n",
            "Wall time: 22.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D9D17mefUrGZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_val_tfidf_tok = m.tfidf_trans(tfidf_vect, X_val_tok)\n",
        "X_test_tfidf_tok = m.tfidf_trans(tfidf_vect, X_test_tok)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wd2b2o_CR-8x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fit LogisticRegression classifier"
      ]
    },
    {
      "metadata": {
        "id": "0YY4lzlmSb8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2f75f47c-77c4-40cb-ef6a-49572a9909f5"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "clf_regr_tok = m.log_regression_train(X_train_tfidf_tok, train_target)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.05 s, sys: 672 ms, total: 1.73 s\n",
            "Wall time: 24.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JDoRXQaCSen4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check the classifier accuracy on validation set:"
      ]
    },
    {
      "metadata": {
        "id": "zYI3hLhdIBTH",
        "colab_type": "code",
        "outputId": "ba942bb8-78fb-451c-ebb7-e7fa9ad1f3d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "lr_acc_val, lr_cvs_val = m.check_acc(clf_regr_tok, X_val_tfidf_tok, val_target)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy:  0.8912\n",
            "Cross validation score:  [0.868      0.86733333 0.88933333 0.87733333 0.88266667]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rl3ZN_-1Vdoc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6d285f3c-269a-4c13-bb68-05efd8bac138"
      },
      "cell_type": "code",
      "source": [
        "lr_acc_test, lr_cvs_test = m.check_acc(clf_regr_tok, X_test_tfidf_tok, test_target)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy:  0.87648\n",
            "Cross validation score:  [0.8882 0.8792 0.8864 0.8848 0.8726]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FNWYuW5es47x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "KPCRpuzDs-Ci",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dcf3a59f-756c-4efc-c2e2-7058e0172af4"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "lr_tn, lr_fp, lr_fn, lr_tp = confusion_matrix(val_target, m.pred_labeles(clf_regr_tok, X_val_tfidf_tok)).ravel()\n",
        "print lr_tn, lr_fp, lr_fn, lr_tp"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3249 456 360 3435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qQZ-fVVqWk0L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save results of model evaluation in DataFrame"
      ]
    },
    {
      "metadata": {
        "id": "qNAkb-GZVo40",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "models_acc = pd.DataFrame({'model_name': [\"log_regr\"], \n",
        "                           'acc_on_val': [lr_acc_val], \\\n",
        "                           'cross_val_score_mean_val': [np.mean(lr_cvs_val)], \\\n",
        "                           'acc_on_test': [lr_acc_test], \n",
        "                           'cross_val_score_mean_test': [np.mean(lr_cvs_test)],\n",
        "                           'TN': lr_tn,\n",
        "                           'FP': lr_fp,\n",
        "                           'FN': lr_fn,\n",
        "                           'TP': lr_tp                      \n",
        "                          })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PMuBGuIyX3AV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "cf81926f-0a61-4cf9-fba1-369a54e0a1b0"
      },
      "cell_type": "code",
      "source": [
        "models_acc"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FN</th>\n",
              "      <th>FP</th>\n",
              "      <th>TN</th>\n",
              "      <th>TP</th>\n",
              "      <th>acc_on_test</th>\n",
              "      <th>acc_on_val</th>\n",
              "      <th>cross_val_score_mean_test</th>\n",
              "      <th>cross_val_score_mean_val</th>\n",
              "      <th>model_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360</td>\n",
              "      <td>456</td>\n",
              "      <td>3249</td>\n",
              "      <td>3435</td>\n",
              "      <td>0.87648</td>\n",
              "      <td>0.8912</td>\n",
              "      <td>0.88224</td>\n",
              "      <td>0.876933</td>\n",
              "      <td>log_regr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    FN   FP    TN    TP  acc_on_test  acc_on_val  cross_val_score_mean_test  \\\n",
              "0  360  456  3249  3435      0.87648      0.8912                    0.88224   \n",
              "\n",
              "   cross_val_score_mean_val model_name  \n",
              "0                  0.876933   log_regr  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "5_WjMZqVXh38",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Other classifiers such as SVC, Random Forest, AdaBoost,  GradientBoostingClassifier were tested as well. They have lower accuracy. Tuning parameters of these classifiers require much time due to sparsity of feature matrix. Results of their evaluation are not listed here."
      ]
    },
    {
      "metadata": {
        "id": "j92RS9W8lNxK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Upload models files to Google disk"
      ]
    },
    {
      "metadata": {
        "id": "6QUevtE7lSac",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from models import MODEL_PATH\n",
        "\n",
        "def upload_to_GD(file_list):\n",
        "  for file in file_list:\n",
        "    upload = drive.CreateFile({'title': file})\n",
        "    upload.SetContentFile(file)\n",
        "    upload.Upload()\n",
        "\n",
        "file_list = [MODEL_PATH[\"TFIDF_VECTORIZER\"], MODEL_PATH[\"LOG_REGR_CLASSIFIER\"]]\n",
        "upload_to_GD(file_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RWG0DOGucF3I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sentiment analysis with Doc2Vec model"
      ]
    },
    {
      "metadata": {
        "id": "lGulb3WHcJ2P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Doc2Vec is an algorithm to convert sentences / documents into numeric vectors. The idea is to get numeric representation of movie reviews and then apply a classification algorithm to the numeric vectors. Length of vectors is taken equal to 100.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "uyLIVhuwcgBT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import Doc2Vec\n",
        "from doc2vec_model import Doc2Vec_Model, DOC2VEC_MODEL_PATH\n",
        "\n",
        "\n",
        "d2v_model = Doc2Vec_Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DxP3Vj9FcyTz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "0ee452dc-d34b-4218-cb97-21e5a1490e8b"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# train and save doc2vec model\n",
        "import multiprocessing\n",
        "cores=multiprocessing.cpu_count()\n",
        "\n",
        "d2v_model.doc2vec_train(X_train_tok, vec_size=100, max_epochs=10, workers=cores)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0\n",
            "iteration 2\n",
            "iteration 4\n",
            "iteration 6\n",
            "iteration 8\n",
            "Model Saved\n",
            "CPU times: user 20min 12s, sys: 28.6 s, total: 20min 40s\n",
            "Wall time: 11min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SL2xn0UYc6K_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load model\n",
        "d2v = Doc2Vec.load(DOC2VEC_MODEL_PATH[\"DOC2VEC\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vdxJfAxdgOGt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "172017cd-9079-48be-eede-bf3656b1a7bd"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# get numeric representation for documents from corpus\n",
        "X_train_d2v = d2v_model.doc2vec_infer(d2v, X_train_tok)\n",
        "X_val_d2v = d2v_model.doc2vec_infer(d2v, X_val_tok)\n",
        "X_test_d2v = d2v_model.doc2vec_infer(d2v, X_test_tok)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 58s, sys: 281 ms, total: 3min 58s\n",
            "Wall time: 3min 58s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8JtU2VS7iti-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train logistic regression on vector representation of the documents and evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "POX0Q8TiisyH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "e180c629-c29c-46fc-cd57-380d8ab1abef"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "lr_d2v_tok = m.log_regression_train(X_train_d2v, train_target)\n",
        "d2v_acc_val, d2v_cvs_val = m.check_acc(lr_d2v_tok, X_val_d2v, val_target)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy:  0.8828\n",
            "Cross validation score:  [0.87333333 0.87466667 0.87933333 0.892      0.894     ]\n",
            "CPU times: user 1min 49s, sys: 3.17 s, total: 1min 52s\n",
            "Wall time: 3min 7s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KYZUQQFUljq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a0c9a151-36ce-42e6-f024-07d4ff0b4bd4"
      },
      "cell_type": "code",
      "source": [
        "d2v_acc_test, d2v_cvs_test = m.check_acc(lr_d2v_tok, X_test_d2v, test_target)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy:  0.87144\n",
            "Cross validation score:  [0.8786 0.8782 0.88   0.8688 0.8588]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cA5_B9Y0t2OZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "B1lzjT6Ptq7U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed06fceb-140c-4323-d82a-aed329f4ab71"
      },
      "cell_type": "code",
      "source": [
        "d2v_tn, d2v_fp, d2v_fn, d2v_tp = confusion_matrix(val_target, m.pred_labeles(lr_d2v_tok, X_val_d2v)).ravel()\n",
        "print d2v_tn, d2v_fp, d2v_fn, d2v_tp"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3255 450 429 3366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9TM8aef7tosE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save results of model evaluation"
      ]
    },
    {
      "metadata": {
        "id": "mJZ7SqHGnSxm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models_acc_d2 = pd.DataFrame({'model_name': [\"d2v\"], \n",
        "                           'acc_on_val': [d2v_acc_val], \\\n",
        "                           'cross_val_score_mean_val': [np.mean(d2v_cvs_val)], \\\n",
        "                           'acc_on_test': [d2v_acc_test], \n",
        "                           'cross_val_score_mean_test': [np.mean(d2v_cvs_test)],\n",
        "                           'TN': d2v_tn,\n",
        "                           'FP': d2v_fp,\n",
        "                           'FN': d2v_fn,\n",
        "                           'TP': d2v_tp})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z1Up-1wdneOC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "22d29131-72d3-4748-f6f3-2a1fc47e8394"
      },
      "cell_type": "code",
      "source": [
        "models_acc = models_acc.append(models_acc_d2)\n",
        "models_acc"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FN</th>\n",
              "      <th>FP</th>\n",
              "      <th>TN</th>\n",
              "      <th>TP</th>\n",
              "      <th>acc_on_test</th>\n",
              "      <th>acc_on_val</th>\n",
              "      <th>cross_val_score_mean_test</th>\n",
              "      <th>cross_val_score_mean_val</th>\n",
              "      <th>model_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360</td>\n",
              "      <td>456</td>\n",
              "      <td>3249</td>\n",
              "      <td>3435</td>\n",
              "      <td>0.87648</td>\n",
              "      <td>0.8912</td>\n",
              "      <td>0.88224</td>\n",
              "      <td>0.876933</td>\n",
              "      <td>log_regr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>429</td>\n",
              "      <td>450</td>\n",
              "      <td>3255</td>\n",
              "      <td>3366</td>\n",
              "      <td>0.87144</td>\n",
              "      <td>0.8828</td>\n",
              "      <td>0.87288</td>\n",
              "      <td>0.882667</td>\n",
              "      <td>d2v</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    FN   FP    TN    TP  acc_on_test  acc_on_val  cross_val_score_mean_test  \\\n",
              "0  360  456  3249  3435      0.87648      0.8912                    0.88224   \n",
              "0  429  450  3255  3366      0.87144      0.8828                    0.87288   \n",
              "\n",
              "   cross_val_score_mean_val model_name  \n",
              "0                  0.876933   log_regr  \n",
              "0                  0.882667        d2v  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "Tjd7phOXl5FC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save the trained model on Google disk"
      ]
    },
    {
      "metadata": {
        "id": "-yNiGeCJl5bC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_list = [DOC2VEC_MODEL_PATH[\"DOC2VEC\"]]\n",
        "upload_to_GD(file_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JAfbsiTIqurx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Sentiment analysis with TextBlob library"
      ]
    },
    {
      "metadata": {
        "id": "cFFOlo3VuE49",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TextBlob library can generate *polarity* *score* for given text. Polarity score is a float within the range [-1;1]"
      ]
    },
    {
      "metadata": {
        "id": "wanKkh0fkNMm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "# get sentiment property for train, validation and test subsets\n",
        "train_pol = np.asarray([TextBlob(text).sentiment[0] for text in X_train_tok]).reshape(-1, 1)\n",
        "val_pol = np.asarray([TextBlob(text).sentiment[0] for text in X_val_tok]).reshape(-1, 1)\n",
        "test_pol = np.asarray([TextBlob(text).sentiment[0] for text in X_test_tok]).reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X7mn5wvxdWLt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Apply logistic regression classifier to polarity scores to classify reviews. For classification a rule based on threshold can be applied. But I found that logistic classifier has better accuracy."
      ]
    },
    {
      "metadata": {
        "id": "d5CLHSnmrDg7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "7e59d653-0029-4e8e-cf38-32c4d34ea022"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pol_clf = m.log_regression_train(train_pol, train_target)\n",
        "pol_acc_val, pol_cvs_val = m.check_acc(pol_clf, val_pol, val_target)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy:  0.7764\n",
            "Cross validation score:  [0.782      0.77866667 0.77866667 0.78266667 0.78133333]\n",
            "CPU times: user 572 ms, sys: 74.9 ms, total: 647 ms\n",
            "Wall time: 2.49 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qxUd0ybptei-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0bee5486-a8b6-4ab7-e659-f34203c8cbd6"
      },
      "cell_type": "code",
      "source": [
        "pol_acc_test, pol_cvs_test = m.check_acc(pol_clf, test_pol, test_target)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean accuracy:  0.77196\n",
            "Cross validation score:  [0.7796 0.7654 0.772  0.7616 0.7788]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_bdpTY68uIsZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "u7HW_FrGuH9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9dde4348-4804-4df1-d229-0a72a8d1b22f"
      },
      "cell_type": "code",
      "source": [
        "pol_tn, pol_fp, pol_fn, pol_tp = confusion_matrix(val_target, m.pred_labeles(pol_clf, val_pol)).ravel()\n",
        "print pol_tn, pol_fp, pol_fn, pol_tp"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2813 892 785 3010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5nH1cU8ut4Kk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models_acc_pol = pd.DataFrame({'model_name': [\"pol\"], \n",
        "                           'acc_on_val': [pol_acc_val], \\\n",
        "                           'cross_val_score_mean_val': [np.mean(pol_cvs_val)], \\\n",
        "                           'acc_on_test': [pol_acc_test], \n",
        "                           'cross_val_score_mean_test': [np.mean(pol_cvs_test)],\n",
        "                           'TN': pol_tn,\n",
        "                           'FP': pol_fp,\n",
        "                           'FN': pol_fn,\n",
        "                           'TP': pol_tp})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8t7D-zWhhQB2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "62d2b39f-1eb0-4534-fee2-97de25b546d4"
      },
      "cell_type": "code",
      "source": [
        "models_acc = models_acc.append(models_acc_pol)\n",
        "models_acc"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FN</th>\n",
              "      <th>FP</th>\n",
              "      <th>TN</th>\n",
              "      <th>TP</th>\n",
              "      <th>acc_on_test</th>\n",
              "      <th>acc_on_val</th>\n",
              "      <th>cross_val_score_mean_test</th>\n",
              "      <th>cross_val_score_mean_val</th>\n",
              "      <th>model_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360</td>\n",
              "      <td>456</td>\n",
              "      <td>3249</td>\n",
              "      <td>3435</td>\n",
              "      <td>0.87648</td>\n",
              "      <td>0.8912</td>\n",
              "      <td>0.88224</td>\n",
              "      <td>0.876933</td>\n",
              "      <td>log_regr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>429</td>\n",
              "      <td>450</td>\n",
              "      <td>3255</td>\n",
              "      <td>3366</td>\n",
              "      <td>0.87144</td>\n",
              "      <td>0.8828</td>\n",
              "      <td>0.87288</td>\n",
              "      <td>0.882667</td>\n",
              "      <td>d2v</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>785</td>\n",
              "      <td>892</td>\n",
              "      <td>2813</td>\n",
              "      <td>3010</td>\n",
              "      <td>0.77196</td>\n",
              "      <td>0.7764</td>\n",
              "      <td>0.77148</td>\n",
              "      <td>0.780667</td>\n",
              "      <td>pol</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    FN   FP    TN    TP  acc_on_test  acc_on_val  cross_val_score_mean_test  \\\n",
              "0  360  456  3249  3435      0.87648      0.8912                    0.88224   \n",
              "0  429  450  3255  3366      0.87144      0.8828                    0.87288   \n",
              "0  785  892  2813  3010      0.77196      0.7764                    0.77148   \n",
              "\n",
              "   cross_val_score_mean_val model_name  \n",
              "0                  0.876933   log_regr  \n",
              "0                  0.882667        d2v  \n",
              "0                  0.780667        pol  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "dpBLq5a7lCGj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural netwoks models"
      ]
    },
    {
      "metadata": {
        "id": "UeZbD9cdp_fZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check frequencies of words."
      ]
    },
    {
      "metadata": {
        "id": "Xnkktsclp9uH",
        "colab_type": "code",
        "outputId": "10e78b8e-b113-4b41-b6eb-15509acf7d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "# find frequencies of words in X_train_tok dataset\n",
        "words_counts = Counter(list(itertools.chain.from_iterable(list(map(lambda x: x.split(), X_train_tok)))))\n",
        "\n",
        "print \"Mean \", np.mean(words_counts.values()) \n",
        "print \"std \", np.std(words_counts.values())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean  33.5034287832453\n",
            "std  334.7098464408595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NYBPDPq5tIwj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16898158-8bbd-409b-e056-c2f523098df4"
      },
      "cell_type": "code",
      "source": [
        "# sort word frequencies\n",
        "sorted_counts = sorted(list(words_counts.values()), reverse=True)\n",
        "sorted_counts[10000:10005]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[21, 21, 21, 21, 21]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "Z-h_lnVkpT3R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It means that top of 10000 words has frequency higher that 22. We'll include top 10000 words in the dictionary."
      ]
    },
    {
      "metadata": {
        "id": "_oQZgl9rtV0u",
        "colab_type": "code",
        "outputId": "f1716127-d791-4be4-90f6-f631e7459ba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from nn_models import NN_Data_Prepare, NN_Model, NN_Train_Predict, NN_MODEL_PATH\n",
        "\n",
        "DICT_SIZE = 10000\n",
        "# create dictionary\n",
        "nn_data_prepare = NN_Data_Prepare(dict_size=DICT_SIZE)\n",
        "nn_data_prepare.create_dict(X_train_tok)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ewbp3eJuM8pw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert lables to float format\n",
        "train_labels = nn_data_prepare.vectorized_labels(train_target)\n",
        "val_labels = nn_data_prepare.vectorized_labels(val_target)\n",
        "test_labels = nn_data_prepare.vectorized_labels(test_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lrVq35Srtpe4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll create two neural networks models."
      ]
    },
    {
      "metadata": {
        "id": "ZPBa0XZ6txRA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural network model 1"
      ]
    },
    {
      "metadata": {
        "id": "46XhaVpGt4R2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first neural network is a dense neural network. It gets one-hot representation of text reviews as input. One-hot representation of a text is a binary vector of length equal to dictionary size. The *i*-th component of the vector equals to 1 if the *i*-th word from the dictionary presents in the text.  "
      ]
    },
    {
      "metadata": {
        "id": "YBOIZzaijLI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a5d330b0-2b2c-45ba-8379-a88fd39c8051"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# create one-hot-encoding representation of input data\n",
        "X_train_ohe = nn_data_prepare.set_ohe(X_train_tok)\n",
        "X_val_ohe = nn_data_prepare.set_ohe(X_val_tok)\n",
        "X_test_ohe = nn_data_prepare.set_ohe(X_test_tok)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 49min 21s, sys: 805 ms, total: 49min 21s\n",
            "Wall time: 49min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WJTOGllMNyft",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create dense model"
      ]
    },
    {
      "metadata": {
        "id": "6Ox6EXb2DhsJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "bd3c9ed7-b30d-49fe-e55c-d5044328a181"
      },
      "cell_type": "code",
      "source": [
        "#from nn_models import NN_Model\n",
        "import nn_models\n",
        "nn_model=nn_models.NN_Model()\n",
        "dense_model = nn_model.dense_model()\n",
        "dense_model.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 16)                160016    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,577\n",
            "Trainable params: 160,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L9uDFrC7Pk21",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fit model"
      ]
    },
    {
      "metadata": {
        "id": "DZxgIzX1Otui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "1e8c6f0b-96de-4ef7-b87c-690fdc7e715a"
      },
      "cell_type": "code",
      "source": [
        "nn_train = NN_Train_Predict()\n",
        "hist = nn_train.compile_and_fit_model(dense_model, X_train_ohe, train_labels, X_val_ohe, val_labels, path_to_save=NN_MODEL_PATH[\"DENSE_MODEL\"])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17500 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "17500/17500 [==============================] - 5s 271us/step - loss: 0.1842 - binary_accuracy: 0.9353 - val_loss: 0.3957 - val_binary_accuracy: 0.8875\n",
            "Epoch 2/20\n",
            "17500/17500 [==============================] - 4s 254us/step - loss: 0.1503 - binary_accuracy: 0.9461 - val_loss: 0.4204 - val_binary_accuracy: 0.8849\n",
            "Epoch 3/20\n",
            "17500/17500 [==============================] - 4s 253us/step - loss: 0.1362 - binary_accuracy: 0.9515 - val_loss: 0.4428 - val_binary_accuracy: 0.8843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4htIHhY2g8hT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "nBmRAhilffkk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "fbc11a53-4113-49da-96fc-edbf2f22d238"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "dense_model = load_model(NN_MODEL_PATH[\"DENSE_MODEL\"])\n",
        "dense_loss_val, dense_acc_val = nn_train.model_evaluate(dense_model, X_val_ohe, val_labels)\n",
        "print \"Validation set. loss: \", dense_loss_val, \", accuracy: \", dense_acc_val \n",
        "dense_loss_test, dense_acc_test = nn_train.model_evaluate(dense_model, X_test_ohe, test_labels)\n",
        "print \"Test set. loss: \", dense_loss_test, \", accuracy: \", dense_acc_test "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7500/7500 [==============================] - 1s 128us/step\n",
            "Validation set. loss:  0.3956817221800486 , accuracy:  0.8874666666348775\n",
            "25000/25000 [==============================] - 3s 103us/step\n",
            "Test set. loss:  0.4294009905424714 , accuracy:  0.87188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g1AKucoyunMM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "CIq7jbkfhwna",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get predicted class labels\n",
        "dense_predicted_classes = nn_train.model_predict_classes(dense_model, X_val_ohe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4KSXnug5iBWI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dense_tn, dense_fp, dense_fn, dense_tp = confusion_matrix(val_labels, dense_predicted_classes.flatten()).ravel()\n",
        "print dense_tn, dense_fp, dense_fn, dense_tp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SRPAmDQRwLoN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save results of evaluation"
      ]
    },
    {
      "metadata": {
        "id": "mKGQLxyNiyFQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models_acc_dense_model = pd.DataFrame({'model_name': [\"dense_model\"], \n",
        "                           'acc_on_val': dense_acc_val, \\\n",
        "                           'cross_val_score_mean_val': None, \\\n",
        "                           'acc_on_test': dense_acc_test, \n",
        "                           'cross_val_score_mean_test': None,\n",
        "                           'TN': dense_tn,\n",
        "                           'FP': dense_fp,\n",
        "                           'FN': dense_fn,\n",
        "                           'TP': dense_tp })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "4a91b9c4-6e03-48f7-c2c4-57936ec9d9ce",
        "id": "PiIP4KcMiyWL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "cell_type": "code",
      "source": [
        "models_acc = models_acc.append(models_acc_dense_model)\n",
        "models_acc"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc_on_test</th>\n",
              "      <th>acc_on_val</th>\n",
              "      <th>cross_val_score_mean_test</th>\n",
              "      <th>cross_val_score_mean_val</th>\n",
              "      <th>model_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.87648</td>\n",
              "      <td>0.891200</td>\n",
              "      <td>0.88224</td>\n",
              "      <td>0.876933</td>\n",
              "      <td>log_regr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.87188</td>\n",
              "      <td>0.887467</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>dense_model</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   acc_on_test  acc_on_val  cross_val_score_mean_test  \\\n",
              "0      0.87648    0.891200                    0.88224   \n",
              "0      0.87188    0.887467                        NaN   \n",
              "\n",
              "   cross_val_score_mean_val   model_name  \n",
              "0                  0.876933     log_regr  \n",
              "0                       NaN  dense_model  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "0BluLkAemIgi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save the trained model on Google disk"
      ]
    },
    {
      "metadata": {
        "id": "USO-M_a5mHtf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_list = [NN_MODEL_PATH[\"DENSE_MODEL\"]]\n",
        "\n",
        "upload_to_GD(file_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f7zNK9N-397R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural network model 2"
      ]
    },
    {
      "metadata": {
        "id": "kGOgd5t64Brq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This neural netowrk is a convolutional neural network (CNN). The text review should be converted in numeric format when each word from the text is replaced with its numeric code. Words that are not in the dictionary, are thrown away."
      ]
    },
    {
      "metadata": {
        "id": "WySYp6IDqtaD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# create numeric representation of input data\n",
        "X_train_numbers = nn_data_prepare.set_to_numbers(X_train_tok)\n",
        "X_val_numbers = nn_data_prepare.set_to_numbers(X_val_tok)\n",
        "X_test_numbers = nn_data_prepare.set_to_numbers(X_test_tok)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5FwnmWw46tXf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Sequences that are fed in CNN should have the same length. Let's check length of the resulting numeric representations for the training set."
      ]
    },
    {
      "metadata": {
        "id": "oEgHX2G4sxsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_len = np.asarray([len(x) for x in X_train_numbers])\n",
        "print \"Mean \", np.mean(X_train_len) \n",
        "print \"std \", np.std(X_train_len)\n",
        "\n",
        "sns.boxplot(X_train_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3I0UiUeH6VA5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the plot above it follows that almost all numeric representations of reviews has less than 500 elements. So let's pad all sequences to the length of 500."
      ]
    },
    {
      "metadata": {
        "id": "CAB_Y9ynPLzJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAXLEN = 500\n",
        "# get padded sequences\n",
        "X_train_padded = nn_data_prepare.padded_set(X_train_numbers, maxlen=MAXLEN)\n",
        "X_val_padded = nn_data_prepare.padded_set(X_val_numbers, maxlen=MAXLEN)\n",
        "X_test_padded = nn_data_prepare.padded_set(X_test_numbers, maxlen=MAXLEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tSJEB0gDPPpp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create cnn model"
      ]
    },
    {
      "metadata": {
        "id": "4YuLrkzrPL7t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnn_model = nn_model.cnn_model()\n",
        "cnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CswHLYESu4LT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fit the model"
      ]
    },
    {
      "metadata": {
        "id": "s2QbvRIGPMDo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nn_train = NN_Train_Predict()\n",
        "hist = nn_train.compile_and_fit_model(cnn_model, X_train_padded, train_labels, X_val_padded, val_labels, path_to_save=NN_MODEL_PATH[\"DENSE_MODEL\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uGV0yF72u-mq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "gk3KPjNBvEI8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "cnn_model = load_model(NN_MODEL_PATH[\"CNN_MODEL\"])\n",
        "cnn_loss_val, cnn_acc_val = nn_train.model_evaluate(cnn_model, X_val_ohe, val_labels)\n",
        "print \"Validation set. loss: \", cnn_loss_val, \", accuracy: \", cnn_acc_val \n",
        "cnn_loss_test, cnn_acc_test = nn_train.model_evaluate(cnn_model, X_test_ohe, test_labels)\n",
        "print \"Test set. loss: \", cnn_loss_test, \", accuracy: \", cnn_acc_test "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7CA1EN9bvgli",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Calculate confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "sHy-g66vv8kD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get predicted class labels\n",
        "cnn_predicted_classes = nn_train.model_predict_classes(cnn_model, X_val_ohe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dXjJ9OlBvsvQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnn_tn, cnn_fp, cnn_fn, cnn_tp = confusion_matrix(val_labels, cnn_predicted_classes.flatten()).ravel()\n",
        "print cnn_tn, cnn_fp, cnn_fn, cnn_tp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ksGmT97wOdt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save result of evaluation"
      ]
    },
    {
      "metadata": {
        "id": "Hh1jUB3mwTVi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models_acc_cnn_model = pd.DataFrame({'model_name': [\"cnn_model\"], \n",
        "                           'acc_on_val': cnn_acc_val, \\\n",
        "                           'cross_val_score_mean_val': None, \\\n",
        "                           'acc_on_test': cnn_acc_test, \n",
        "                           'cross_val_score_mean_test': None,\n",
        "                           'TN': cnn_tn,\n",
        "                           'FP': cnn_fp,\n",
        "                           'FN': cnn_fn,\n",
        "                           'TP': cnn_tp })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "woIeFdSWw4La",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "models_acc = models_acc.append(models_acc_cnn_model)\n",
        "models_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H3Ybdt_9mQni",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save trained model on Google disk"
      ]
    },
    {
      "metadata": {
        "id": "wdrABrF7PMBH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_list = [NN_MODEL_PATH[\"CNN_MODEL\"]]\n",
        "\n",
        "upload_to_GD(file_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HCK99vZ70hEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "35538bfe-fff1-4cb6-f6c9-cb91e42ed85d"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(107.33857142857143, 80.126088123402)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "fFK0fZMk09oa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "96bb1f20-f5bb-4678-c675-ebb8df8a5064"
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.boxplot(result)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/seaborn/categorical.py:454: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
            "  box_data = remove_na(group_data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb7ec013bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFKCAYAAACQMm9DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "35MfhskErZk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "62f1d80b-d8d0-4078-9912-93af84e5ea90"
      },
      "cell_type": "code",
      "source": [
        "dnn_emd = nn_models.dnn_emb(hid_out=250)\n",
        "nn_train = NN_Train(batch_size=64)\n",
        "hist = nn_train.compile_and_fit_model(dnn_emd, X_train_emb, train_labels, X_val_emb, val_labels, lr=0.001)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17500 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "17500/17500 [==============================] - 4s 235us/step - loss: 0.4126 - binary_accuracy: 0.7988 - val_loss: 0.3039 - val_binary_accuracy: 0.8779\n",
            "Epoch 2/20\n",
            "17500/17500 [==============================] - 3s 171us/step - loss: 0.1250 - binary_accuracy: 0.9553 - val_loss: 0.3744 - val_binary_accuracy: 0.8717\n",
            "Epoch 3/20\n",
            "17500/17500 [==============================] - 3s 172us/step - loss: 0.0211 - binary_accuracy: 0.9933 - val_loss: 0.7101 - val_binary_accuracy: 0.8665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CE1slFkbCoL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "a7ef79ef-3f67-48fe-f69f-cf6c2d945504"
      },
      "cell_type": "code",
      "source": [
        "cnn = nn_models.dnn_emb(hid_out=100)\n",
        "nn_train = NN_Train(batch_size=32)\n",
        "hist = nn_train.compile_and_fit_model(cnn, X_train_emb, train_labels, X_val_emb, val_labels, lr=0.001)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17500 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "17500/17500 [==============================] - 8s 479us/step - loss: 0.4399 - binary_accuracy: 0.7773 - val_loss: 0.2920 - val_binary_accuracy: 0.8796\n",
            "Epoch 2/20\n",
            "17500/17500 [==============================] - 6s 314us/step - loss: 0.1268 - binary_accuracy: 0.9587 - val_loss: 0.3534 - val_binary_accuracy: 0.8679\n",
            "Epoch 3/20\n",
            "17500/17500 [==============================] - 6s 315us/step - loss: 0.0179 - binary_accuracy: 0.9955 - val_loss: 0.6314 - val_binary_accuracy: 0.8665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "23Eh-F9oz8os",
        "colab_type": "code",
        "outputId": "f2d361b9-0aa2-4144-e02b-c91e80a1590c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "nn_models =  NN_Models()\n",
        "base_model = nn_models.baseline_model(output=16)\n",
        "\n",
        "nn_train = NN_Train(batch_size=512)\n",
        "hist = nn_train.compile_and_fit_model(base_model, X_train, train_labels, X_val, val_labels, lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17500 samples, validate on 7500 samples\n",
            "Epoch 1/20\n",
            "17500/17500 [==============================] - 5s 266us/step - loss: 0.6270 - binary_accuracy: 0.6515 - val_loss: 0.5170 - val_binary_accuracy: 0.8237\n",
            "Epoch 2/20\n",
            "17500/17500 [==============================] - 1s 80us/step - loss: 0.4967 - binary_accuracy: 0.7977 - val_loss: 0.4003 - val_binary_accuracy: 0.8748\n",
            "Epoch 3/20\n",
            "17500/17500 [==============================] - 1s 80us/step - loss: 0.4018 - binary_accuracy: 0.8533 - val_loss: 0.3344 - val_binary_accuracy: 0.8788\n",
            "Epoch 4/20\n",
            "17500/17500 [==============================] - 1s 80us/step - loss: 0.3315 - binary_accuracy: 0.8877 - val_loss: 0.3082 - val_binary_accuracy: 0.8829\n",
            "Epoch 5/20\n",
            "17500/17500 [==============================] - 1s 81us/step - loss: 0.2725 - binary_accuracy: 0.9080 - val_loss: 0.3001 - val_binary_accuracy: 0.8844\n",
            "Epoch 6/20\n",
            "17500/17500 [==============================] - 1s 81us/step - loss: 0.2305 - binary_accuracy: 0.9281 - val_loss: 0.3229 - val_binary_accuracy: 0.8861\n",
            "Epoch 7/20\n",
            "17500/17500 [==============================] - 1s 80us/step - loss: 0.1981 - binary_accuracy: 0.9373 - val_loss: 0.3363 - val_binary_accuracy: 0.8856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zyK2QUA3eIKM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ]
    },
    {
      "metadata": {
        "id": "jE5utiGneSZ2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Accuracy of 4 constructed models are presented in the table below"
      ]
    },
    {
      "metadata": {
        "id": "78enfC9Pws5A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = df[cols] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EPKMMfLxeYSz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the table above it follows that "
      ]
    },
    {
      "metadata": {
        "id": "wYNWXwZY_TrS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Further steps "
      ]
    },
    {
      "metadata": {
        "id": "yi73n5Xh_lzs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To take into account 2- and 3-, etc-grams presented in the text, another neural network model can be created. \n",
        "As input, the model takes padded sequences. Each sequence consists of dictionary indexes of 1- and 2-grams that present in the text.\n",
        "In other words, words in the initial review text is replaced with their indexes from the dictionary. The resulted sequence is extended with indexes of 2-, 3-, etc-grams and then padded to the predefined length. I assume that a dense network with 2-3 hidden layers can be used. \n",
        "\n",
        "To improve quality of the models, constructed above, the following steps may be taken:\n",
        "\n",
        "1. tune hyperparameters of neural networks (number of hidden layers, number of neurons in hidden layers, learning rate, etc) with e.g. *hyperopt* library\n",
        "2. consider voting ensemble classifier based on on hard or soft voting (soft voting when class labels are predicted based on the predicted probabilities; hard voting is a majority-based voting)\n",
        "3. investigate examples on which classifiers fail. It may help to improve preprocessing to avoid classifiers errors\n",
        "3. check if removing stopwords really improves the model quality. It may turn out that the model constructed on data with stopwords yields better accuracy\n",
        "4. check if dictionary size influence strongly the model quality\n",
        "\n",
        "  \n"
      ]
    },
    {
      "metadata": {
        "id": "O8YpLleI_mc_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}